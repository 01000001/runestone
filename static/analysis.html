

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Algorithm Analysis &mdash; Problem Solving with Algorithms and Data Structures 3.0 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/video.css" type="text/css" />
    <link rel="stylesheet" href="_static/edu-python.css" type="text/css" />
    <link rel="stylesheet" href="_static/codemirror.css" type="text/css" />
    <link rel="stylesheet" href="_static/theme/default.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/simplemodal.js"></script>
    <script type="text/javascript" src="_static/jquery.textarea.js"></script>
    <script type="text/javascript" src="_static/edu-python.js"></script>
    <script type="text/javascript" src="_static/bookfuncs.js"></script>
    <script type="text/javascript" src="_static/codemirror.js"></script>
    <script type="text/javascript" src="_static/python.js"></script>
    <script type="text/javascript" src="_static/skulpt.js"></script>
    <script type="text/javascript" src="_static/builtin.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Problem Solving with Algorithms and Data Structures 3.0 documentation" href="index.html" />
    <link rel="next" title="Basic Data Structures" href="basic.html" />
    <link rel="prev" title="Introduction" href="introduction.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="basic.html" title="Basic Data Structures"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="introduction.html" title="Introduction"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">Problem Solving with Algorithms and Data Structures 3.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Algorithm Analysis</a><ul>
<li><a class="reference internal" href="#objectives">Objectives</a></li>
<li><a class="reference internal" href="#what-is-algorithm-analysis">What Is Algorithm Analysis?</a><ul>
<li><a class="reference internal" href="#big-o-notation">Big-O Notation</a></li>
<li><a class="reference internal" href="#an-anagram-detection-example">An Anagram Detection Example</a><ul>
<li><a class="reference internal" href="#solution-1-checking-off">Solution 1: Checking Off</a></li>
<li><a class="reference internal" href="#solution-2-sort-and-compare">Solution 2: Sort and Compare</a></li>
<li><a class="reference internal" href="#solution-3-brute-force">Solution 3: Brute Force</a></li>
<li><a class="reference internal" href="#solution-4-count-and-compare">Solution 4: Count and Compare</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#performance-of-python-data-structures">Performance of Python Data Structures</a><ul>
<li><a class="reference internal" href="#lists">Lists</a></li>
<li><a class="reference internal" href="#dictionaries">Dictionaries</a></li>
</ul>
</li>
<li><a class="reference internal" href="#summary">Summary</a></li>
<li><a class="reference internal" href="#key-terms">Key Terms</a></li>
<li><a class="reference internal" href="#discussion-questions">Discussion Questions</a></li>
<li><a class="reference internal" href="#programming-exercises">Programming Exercises</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="introduction.html"
                        title="previous chapter">Introduction</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="basic.html"
                        title="next chapter">Basic Data Structures</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/analysis.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="algorithm-analysis">
<h1>Algorithm Analysis<a class="headerlink" href="#algorithm-analysis" title="Permalink to this headline">¶</a></h1>
<p>{chap:anal}</p>
<div class="section" id="objectives">
<h2>Objectives<a class="headerlink" href="#objectives" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>To understand why algorithm analysis is important.</li>
<li>To be able to use “Big-O” to describe execution time.</li>
<li>To understand the “Big-O” execution time of common operations on
Python lists and dictionaries.</li>
<li>To understand how the implementation of Python data impacts algorithm
analysis.</li>
<li>To understand how to benchmark simple Python programs.</li>
</ul>
<p>{escapeinside={#//}{^^M}}</p>
</div>
<div class="section" id="what-is-algorithm-analysis">
<h2>What Is Algorithm Analysis?<a class="headerlink" href="#what-is-algorithm-analysis" title="Permalink to this headline">¶</a></h2>
<p>{knuth} It is very common for beginning computer science students to
compare their programs with one another. You may also have noticed that
it is common for computer programs to look very similar, especially the
simple ones. An interesting question often arises. When two programs
solve the same problem but look different, is one program better than
the other?</p>
<p>In order to answer this question, we need to remember that there is an
important difference between a program and the underlying algorithm that
the program is representing. As we stated in Chapter 1, an algorithm is
a generic, step-by-step list of instructions for solving a problem. It
is a method for solving any instance of the problem such that given a
particular input, the algorithm produces the desired result. A program,
on the other hand, is an algorithm that has been encoded into some
programming language. There may be many programs for the same algorithm,
depending on the programmer and the programming language being used.</p>
<p>To explore this difference further, consider the function shown in
Listing&nbsp;{sum1}. This function solves a familiar problem, computing the
sum of the first <em>n</em> integers. The algorithm uses the idea of an
accumulator variable that is initialized to 0. The solution then
iterates through the <em>n</em> integers, adding each to the accumulator.</p>
<div class="highlight-python"><pre>[caption={Summation of the First \textit{n} Integers},label=sum1,index={sumOfN},float=htb]
def sumOfN(n):
   theSum = 0
   for i in range(1,n+1):
       theSum = theSum + i

   return theSum</pre>
</div>
<p>Now look at the function in Listing&nbsp;{sum2}. At first glance it may look
strange, but upon further inspection you can see that this function is
essentially doing the same thing as the previous one. The reason this is
not obvious is poor coding. We did not use good identifier names to
assist with readability, and we used an extra assignment statement
during the accumulation step that was not really necessary.</p>
<div class="highlight-python"><pre>[caption={Another Summation of the First \textit{n} Integers},label=sum2,float=htb]
def foo(tom):
    fred = 0
    for bill in range(1,tom+1):
       barney = bill
       fred = fred + barney

     return fred</pre>
</div>
<p>The question we raised earlier asked whether one function is better than
another. The answer depends on your criteria. The function <tt class="docutils literal"><span class="pre">sumOfN</span></tt> is
certainly better than the function <tt class="docutils literal"><span class="pre">foo</span></tt> if you are concerned with
readability. In fact, you have probably seen many examples of this in
your introductory programming course since one of the goals there is to
help you write programs that are easy to read and easy to understand. In
this course, however, we are also interested in characterizing the
algorithm itself. (We certainly hope that you will continue to strive to
write readable, understandable code.)</p>
<p>Algorithm analysis is concerned with comparing algorithms based upon the
amount of computing resources that each algorithm uses. We want to be
able to consider two algorithms and say that one is better than the
other because it is more efficient in its use of those resources or
perhaps because it simply uses fewer. From this perspective, the two
functions above seem very similar. They both use essentially the same
algorithm to solve the summation problem.</p>
<p>At this point, it is important to think more about what we really mean
by computing resources. There are two different ways to look at this.
One way is to consider the amount of space or memory an algorithm
requires to solve the problem. The amount of space required by a problem
solution is typically dictated by the problem instance itself. Every so
often, however, there are algorithms that have very specific space
requirements, and in those cases we will be very careful to explain the
variations.</p>
<p>As an alternative to space requirements, we can analyze and compare
algorithms based on the amount of time they require to execute. This
measure is sometimes referred to as the “execution time” or “running
time” of the algorithm. One way we can measure the execution time for
the function <tt class="docutils literal"><span class="pre">sumOfN</span></tt> is to do a benchmark analysis. This means that
we will track the actual time required for the program to compute its
result. In Python, we can benchmark a function by noting the starting
time and ending time with respect to the system we are using. In the
<tt class="docutils literal"><span class="pre">time</span></tt> module there is a function called <tt class="docutils literal"><span class="pre">time</span></tt> that will return the
current system clock time in seconds since some arbitrary starting
point. By calling this function twice, at the beginning and at the end,
and then computing the difference, we can get an exact number of seconds
(fractions in most cases) for execution.</p>
<div class="highlight-python"><pre>[caption={Timing the Summation},label=sum11,index={sumOfN},float=htb]
import time

def sumOfN2(n):
   start = time.time()

   theSum = 0
   for i in range(1,n+1):
      theSum = theSum + i

   end = time.time()

   return theSum,end-start</pre>
</div>
<p>Listing {sum11} shows the original <tt class="docutils literal"><span class="pre">sumOfN</span></tt> function with the timing
calls embedded before and after the summation. The function returns a
tuple consisting of the result and the amount of time (in seconds)
required for the calculation. If we perform 5 invocations of the
function, each computing the sum of the first 10,000 integers, we get
the following:</p>
<p>{}</p>
<div class="highlight-python"><div class="highlight"><pre><span class="go">&gt;&gt;&gt;for i in range(5):</span>
<span class="go">       print(&quot;Sum is %d required %10.7f seconds&quot;%sumOfN(10000))</span>
<span class="go">Sum is 50005000 required  0.0018950 seconds</span>
<span class="go">Sum is 50005000 required  0.0018620 seconds</span>
<span class="go">Sum is 50005000 required  0.0019171 seconds</span>
<span class="go">Sum is 50005000 required  0.0019162 seconds</span>
<span class="go">Sum is 50005000 required  0.0019360 seconds</span>
</pre></div>
</div>
<p>We discover that the time is fairly consistent and it takes on average
about 0.0019 seconds to execute that code. What if we run the function
adding the first 100,000 integers?</p>
<div class="highlight-python"><div class="highlight"><pre><span class="go">&gt;&gt;&gt;for i in range(5):</span>
<span class="go">       print(&quot;Sum is %d required %10.7f seconds&quot;%sumOfN(100000))</span>
<span class="go">Sum is 5000050000 required  0.0199420 seconds</span>
<span class="go">Sum is 5000050000 required  0.0180972 seconds</span>
<span class="go">Sum is 5000050000 required  0.0194821 seconds</span>
<span class="go">Sum is 5000050000 required  0.0178988 seconds</span>
<span class="go">Sum is 5000050000 required  0.0188949 seconds</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
<p>Again, the time required for each run, although longer, is very
consistent, averaging about 10 times more seconds. For <tt class="docutils literal"><span class="pre">n</span></tt> equal to
1,000,000 we get:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="go">&gt;&gt;&gt;for i in range(5):</span>
<span class="go">       print(&quot;Sum is %d required %10.7f seconds&quot;%sumOfN(1000000))</span>
<span class="go">Sum is 500000500000 required  0.1948988 seconds</span>
<span class="go">Sum is 500000500000 required  0.1850290 seconds</span>
<span class="go">Sum is 500000500000 required  0.1809771 seconds</span>
<span class="go">Sum is 500000500000 required  0.1729250 seconds</span>
<span class="go">Sum is 500000500000 required  0.1646299 seconds</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
<p>In this case, the average again turns out to be about 10 times the
previous.</p>
<p>{} Now consider Listing&nbsp;{sum3}, which shows a different means of solving
the summation problem. This function, <tt class="docutils literal"><span class="pre">sumOfN3</span></tt>, takes advantage of a
closed equation <span class="math">\($\sum_{i=1}^{n} i = \frac {(n)(n+1)}{2}$\)</span> to
compute the sum of the first <tt class="docutils literal"><span class="pre">n</span></tt> integers without iterating.</p>
<div class="highlight-python"><pre>[caption={Summation Without Iteration},label=sum3,float=htb]
def sumOfN3(n):
   return (n*(n+1))/2</pre>
</div>
<p>If we do the same benchmark measurement for <tt class="docutils literal"><span class="pre">sumOfN3</span></tt>, using five
different values for <tt class="docutils literal"><span class="pre">n</span></tt> (10,000, 100,000, 1,000,000, 10,000,000, and
100,000,000), we get the following results:</p>
<div class="highlight-python"><pre>Sum is 50005000 required 0.00000095 seconds
Sum is 5000050000 required 0.00000191 seconds
Sum is 500000500000 required 0.00000095 seconds
Sum is 50000005000000 required 0.00000095 seconds
Sum is 5000000050000000 required 0.00000119 seconds</pre>
</div>
<p>There are two important things to notice about this output. First, the
times recorded above are shorter than any of the previous examples.
Second, they are very consistent no matter what the value of <tt class="docutils literal"><span class="pre">n</span></tt>. It
appears that <tt class="docutils literal"><span class="pre">sumOfN3</span></tt> is hardly impacted by the number of integers
being added.</p>
<p>But what does this benchmark really tell us? Intuitively, we can see
that the iterative solutions seem to be doing more work since some
program steps are being repeated. This is likely the reason it is taking
longer. Also, the time required for the iterative solution seems to
increase as we increase the value of <tt class="docutils literal"><span class="pre">n</span></tt>. However, there is a problem.
If we ran the same function on a different computer or used a different
programming language, we would likely get different results. It could
take even longer to perform <tt class="docutils literal"><span class="pre">sumOfN3</span></tt> if the computer were older.</p>
<p>We need a better way to characterize these algorithms with respect to
execution time. The benchmark technique computes the actual time to
execute. It does not really provide us with a useful measurement,
because it is dependent on a particular machine, program, time of day,
compiler, and programming language. Instead, we would like to have a
characterization that is independent of the program or computer being
used. This measure would then be useful for judging the algorithm alone
and could be used to compare algorithms across implementations.</p>
<div class="section" id="big-o-notation">
<h3>Big-O Notation<a class="headerlink" href="#big-o-notation" title="Permalink to this headline">¶</a></h3>
<p>When trying to characterize an algorithm’s efficiency in terms of
execution time, independent of any particular program or computer, it is
important to quantify the number of operations or steps that the
algorithm will require. If each of these steps is considered to be a
basic unit of computation, then the execution time for an algorithm can
be expressed as the number of steps required to solve the problem.
Deciding on an appropriate basic unit of computation can be a
complicated problem and will depend on how the algorithm is implemented.</p>
<p>A good basic unit of computation for comparing the summation algorithms
shown earlier might be to count the number of assignment statements
performed to compute the sum. In the function <tt class="docutils literal"><span class="pre">sumOfN</span></tt>, the number of
assignment statements is 1 (<span class="math">\(theSum =
0\)</span>) plus the value of <em>n</em> (the number of times we perform
<span class="math">\(theSum=theSum+i\)</span>). We can denote this by a function, call it T,
where <span class="math">\(T(n)=1 + n\)</span>. The parameter <em>n</em> is often referred to as
the “size of the problem,” and we can read this as “<em>T*(*n</em>) is the time
it takes to solve a problem of size <em>n</em>, namely 1+*n* steps.”</p>
<p>In the summation functions given above, it makes sense to use the number
of terms in the summation to denote the size of the problem. We can then
say that the sum of the first 100,000 integers is a bigger instance of
the summation problem than the sum of the first 1,000. Because of this,
it might seem reasonable that the time required to solve the larger case
would be greater than for the smaller case. Our goal then is to show how
the algorithm’s execution time changes with respect to the size of the
problem.</p>
<p>Computer scientists prefer to take this analysis technique one step
further. It turns out that the exact number of operations is not as
important as determining the most dominant part of the <span class="math">\(T(n)\)</span>
function. In other words, as the problem gets larger, some portion of
the <span class="math">\(T(n)\)</span> function tends to overpower the rest. This dominant
term is what, in the end, is used for comparison. The <strong>order of
magnitude</strong> function describes the part of <span class="math">\(T(n)\)</span> that increases
the fastest as the value of <em>n</em> increases. Order of magnitude is often
called <strong>Big-O</strong> notation (for “order”) and written as
<span class="math">\(O(f(n))\)</span>. It provides a useful approximation to the actual
number of steps in the computation. The function <span class="math">\(f(n)\)</span> provides
a simple representation of the dominant part of the original
<span class="math">\(T(n)\)</span>.</p>
<p>In the above example, <span class="math">\(T(n)=1+n\)</span>. As <em>n</em> gets large, the
constant 1 will become less and less significant to the final result. If
we are looking for an approximation for <span class="math">\(T(n)\)</span>, then we can drop
the 1 and simply say that the running time is <span class="math">\(O(n)\)</span>. It is
important to note that the 1 is certainly significant for
<span class="math">\(T(n)\)</span>. However, as <em>n</em> gets large, our approximation will be
just as accurate without it.</p>
<p>As another example, suppose that for some algorithm, the exact number of
steps is <span class="math">\(T(n)=5n^{2}+27n+1005\)</span>. When <em>n</em> is small, say 1 or 2,
the constant 1005 seems to be the dominant part of the function.
However, as <em>n</em> gets larger, the <span class="math">\(n^{2}\)</span> term becomes the most
important. In fact, when <em>n</em> is really large, the other two terms become
insignificant in the role that they play in determining the final
result. Again, to approximate <span class="math">\(T(n)\)</span> as <em>n</em> gets large, we can
ignore the other terms and focus on <span class="math">\(5n^{2}\)</span>. In addition, the
coefficient <span class="math">\(5\)</span> becomes insignificant as <em>n</em> gets large. We
would say then that the function <span class="math">\(T(n)\)</span> has an order of
magnitude <span class="math">\(f(n)=n^{2}\)</span>, or simply that it is <span class="math">\(O(n^{2})\)</span>.</p>
<p>Although we do not see this in the summation example, sometimes the
performance of an algorithm depends on the exact values of the data
rather than simply the size of the problem. For these kinds of
algorithms we need to characterize their performance in terms of best
case, <strong>worst case</strong>, or <strong>average case</strong> performance. The worst case
performance refers to a particular data set where the algorithm performs
especially poorly. Whereas a different data set for the exact same
algorithm might have extraordinarily good performance. However, in most
cases the algorithm performs somewhere in between these two extremes
(average case). It is important for a computer scientist to understand
these distinctions so they are not misled by one particular case.</p>
<table border="1" class="docutils">
<colgroup>
<col width="57%" />
<col width="43%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head"><strong>f(n)</strong></th>
<th class="head"><strong>Name</strong></th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td><span class="math">\(1\)</span></td>
<td>Constant</td>
</tr>
<tr class="row-odd"><td><span class="math">\(\log n\)</span></td>
<td>Logarithmic</td>
</tr>
<tr class="row-even"><td><span class="math">\(n\)</span></td>
<td>Linear</td>
</tr>
<tr class="row-odd"><td><span class="math">\(n\log n\)</span></td>
<td>Log Linear</td>
</tr>
<tr class="row-even"><td><span class="math">\(n^{2}\)</span></td>
<td>Quadratic</td>
</tr>
<tr class="row-odd"><td><span class="math">\(n^{3}\)</span></td>
<td>Cubic</td>
</tr>
<tr class="row-even"><td><span class="math">\(2^{n}\)</span></td>
<td>Exponential</td>
</tr>
</tbody>
</table>
<blockquote>
<div>{Common Functions for Big-O} {fntable}</div></blockquote>
<p>A number of very common order of magnitude functions will come up over
and over as you study algorithms. These are shown in Table&nbsp;{fntable}. In
order to decide which of these functions is the dominant part of any
<span class="math">\(T(n)\)</span> function, we must see how they compare with one another
as <em>n</em> gets large. Figure&nbsp;{graphfigure} shows graphs of the common
functions from Table&nbsp;{fntable}. Notice that when <em>n</em> is small, the
functions are not very well defined with respect to one another. It is
hard to tell which is dominant. However, as <em>n</em> grows, there is a
definite relationship and it is easy to see how they compare with one
another.</p>
<blockquote>
<div><img alt="image" src="_images/newplot.png" /> {Plot of Common Big-O Functions} {graphfigure}</div></blockquote>
<p>As a final example, suppose that we have the fragment of Python code
shown in Listing {dummycode}. Although this program does not really do
anything, it is instructive to see how we can take actual code and
analyze performance.</p>
<div class="highlight-python"><pre>[caption={Example Python Code},label=dummycode,float=htbp]
a=5
b=6
c=10
for i in range(n):
   for j in range(n):
      x = i * i
      y = j * j
      z = i * j
for k in range(n):
   w = a*k + 45
   v = b*b
d = 33</pre>
</div>
<p>The number of assignment operations is the sum of four terms. The first
term is the constant 3, representing the three assignment statements at
the start of the fragment. The second term is <span class="math">\(3n^{2}\)</span>, since
there are three statements that are performed <span class="math">\(n^{2}\)</span> times due
to the nested iteration. The third term is <span class="math">\(2n\)</span>, two statements
iterated <em>n</em> times. Finally, the fourth term is the constant 1,
representing the final assignment statement. This gives us
<span class="math">\(T(n)=3+3n^{2}+2n+1=3n^{2}+2n+4\)</span>. By looking at the exponents,
we can easily see that the <span class="math">\(n^{2}\)</span> term will be dominant and
therefore this fragment of code is <span class="math">\(O(n^{2})\)</span>. Note that all of
the other terms as well as the coefficient on the dominant term can be
ignored as <em>n</em> grows larger.</p>
<blockquote>
<div><img alt="image1" src="_images/newplot2.png" /> {Comparing <span class="math">\(T(n)\)</span> with Common Big-O Functions}
{graphfigure2}</div></blockquote>
<p>Figure&nbsp;{graphfigure2} shows a few of the common Big-O functions as they
compare with the <span class="math">\(T(n)\)</span> function discussed above. Note that
<span class="math">\(T(n)\)</span> is initially larger than the cubic function. However, as
n grows, the cubic function quickly overtakes <span class="math">\(T(n)\)</span>. It is easy
to see that <span class="math">\(T(n)\)</span> then follows the quadratic function as
<span class="math">\(n\)</span> continues to grow.</p>
</div>
<div class="section" id="an-anagram-detection-example">
<h3>An Anagram Detection Example<a class="headerlink" href="#an-anagram-detection-example" title="Permalink to this headline">¶</a></h3>
<p>A good example problem for showing algorithms with different orders of
magnitude is the classic anagram detection problem for strings. One
string is an anagram of another if the second is simply a rearrangement
of the first. For example, <tt class="docutils literal"><span class="pre">'heart'</span></tt> and <tt class="docutils literal"><span class="pre">'earth'</span></tt> are anagrams. The
strings <tt class="docutils literal"><span class="pre">'python'</span></tt> and <tt class="docutils literal"><span class="pre">'typhon'</span></tt> are anagrams as well. For the sake
of simplicity, we will assume that the two strings in question are of
equal length and that they are made up of symbols from the set of 26
lowercase alphabetic characters. Our goal is to write a boolean function
that will take two strings and return whether they are anagrams.</p>
<div class="section" id="solution-1-checking-off">
<h4>Solution 1: Checking Off<a class="headerlink" href="#solution-1-checking-off" title="Permalink to this headline">¶</a></h4>
<p>Our first solution to the anagram problem will check to see that each
character in the first string actually occurs in the second. If it is
possible to “checkoff” each character, then the two strings must be
anagrams. Checking off a character will be accomplished by replacing it
with the special Python value <tt class="docutils literal"><span class="pre">None</span></tt>. However, since strings in Python
are immutable, the first step in the process will be to convert the
second string to a list. Each character from the first string can be
checked against the characters in the list and if found, checked off by
replacement. Listing&nbsp;{ana1} shows this function.</p>
<div class="highlight-python"><pre>[caption={Checking Off},label=ana1,index={anagramSolution},float=htb]
def anagramSolution1(s1,s2):
    alist = list(s2)

    pos1 = 0
    stillOK = True

    while pos1 &lt; len(s1) and stillOK:
        pos2 = 0
        found = False
        while pos2 &lt; len(alist) and not found:
            if s1[pos1] == alist[pos2]:
                found = True
            else:
                pos2 = pos2 + 1

        if found:
            alist[pos2] = None
        else:
            stillOK = False

        pos1 = pos1 + 1

    return stillOK</pre>
</div>
<p>To analyze this algorithm, we need to note that each of the <em>n</em>
characters in <tt class="docutils literal"><span class="pre">s1</span></tt> will cause an iteration through up to <em>n</em>
characters in the list from <tt class="docutils literal"><span class="pre">s2</span></tt>. Each of the <em>n</em> positions in the
list will be visited once to match a character from <tt class="docutils literal"><span class="pre">s1</span></tt>. The number
of visits then becomes the sum of the integers from 1 to <em>n</em>. We stated
earlier that this can be written as
<span class="math">\($\sum_{i=1}^{n} i = \frac {n(n+1)}{2} = \frac {1}{2}n^{2} + \frac {1}{2}n $\)</span>
As <em>n</em> gets large, the <span class="math">\(n^{2}\)</span> term will dominate the
<span class="math">\(n\)</span> term and the <span class="math">\(\frac {1}{2}\)</span> can be ignored.
Therefore, this solution is <span class="math">\(O(n^{2})\)</span>.</p>
</div>
<div class="section" id="solution-2-sort-and-compare">
<h4>Solution 2: Sort and Compare<a class="headerlink" href="#solution-2-sort-and-compare" title="Permalink to this headline">¶</a></h4>
<p>Another solution to the anagram problem will make use of the fact that
even though <tt class="docutils literal"><span class="pre">s1</span></tt> and <tt class="docutils literal"><span class="pre">s2</span></tt> are different, they are anagrams only if
they consist of exactly the same characters. So, if we begin by sorting
each string alphabetically, from a to z, we will end up with the same
string if the original two strings are anagrams. Listing&nbsp;{ana2} shows
this solution. Again, in Python we can use the built-in <tt class="docutils literal"><span class="pre">sort</span></tt> method
on lists by simply converting each string to a list at the start.</p>
<div class="highlight-python"><pre>[caption={Sort and Compare},label=ana2,index={anagramSolution2},float=htb]
def anagramSolution2(s1,s2):
    alist1 = list(s1)
    alist2 = list(s2)

    alist1.sort()
    alist2.sort()

    pos = 0
    matches = True

    while pos &lt; len(s1) and matches:
        if alist1[pos]==alist2[pos]:
            pos = pos + 1
        else:
            matches = False

    return matches</pre>
</div>
<p>At first glance you may be tempted to think that this algorithm is
<span class="math">\(O(n)\)</span>, since there is one simple iteration to compare the <em>n</em>
characters after the sorting process. However, the two calls to the
Python <tt class="docutils literal"><span class="pre">sort</span></tt> method are not without their own cost. As we will see in
a later chapter, sorting is typically either <span class="math">\(O(n^{2})\)</span> or
<span class="math">\(O(n\log n)\)</span>, so the sorting operations dominate the iteration.
In the end, this algorithm will have the same order of magnitude as that
of the sorting process.</p>
</div>
<div class="section" id="solution-3-brute-force">
<h4>Solution 3: Brute Force<a class="headerlink" href="#solution-3-brute-force" title="Permalink to this headline">¶</a></h4>
<p>A <strong>brute force</strong> technique for solving a problem typically tries to
exhaust all possibilities. For the anagram detection problem, we can
simply generate a list of all possible strings using the characters from
<tt class="docutils literal"><span class="pre">s1</span></tt> and then see if <tt class="docutils literal"><span class="pre">s2</span></tt> occurs. However, there is a difficulty
with this approach. When generating all possible strings from <tt class="docutils literal"><span class="pre">s1</span></tt>,
there are <em>n</em> possible first characters, <span class="math">\(n-1\)</span> possible
characters for the second position, <span class="math">\(n-2\)</span> for the third, and so
on. The total number of candidate strings is
<span class="math">\(n*(n-1)*(n-2)*...*3*2*1\)</span>, which is <span class="math">\(n!\)</span>. Although some
of the strings may be duplicates the program cannot know this ahead of
time and so it will still generate <span class="math">\(n!\)</span> different strings.</p>
<p>It turns out that <span class="math">\(n!\)</span> grows even faster than <span class="math">\(2^{n}\)</span> as
<em>n</em> gets large. In fact, if <tt class="docutils literal"><span class="pre">s1</span></tt> were 20 characters long, there would
be <span class="math">\(20!=2,432,902,008,176,640,000\)</span> possible candidate strings.
If we processed one possibility every second, it would still take us
77,146,816,596 years to go through the entire list. This is probably not
going to be a good solution.</p>
</div>
<div class="section" id="solution-4-count-and-compare">
<h4>Solution 4: Count and Compare<a class="headerlink" href="#solution-4-count-and-compare" title="Permalink to this headline">¶</a></h4>
<p>Our final solution to the anagram problem takes advantage of the fact
that any two anagrams will have the same number of a’s, the same number
of b’s, the same number of c’s, and so on. In order to decide whether
two strings are anagrams, we will first count the number of times each
character occurs. Since there are 26 possible characters, we can use a
list of 26 counters, one for each possible character. Each time we see a
particular character, we will increment the counter at that position. In
the end, if the two lists of counters are identical, the strings must be
anagrams. Listing&nbsp;{ana4} shows this solution.</p>
<div class="highlight-python"><pre>[caption={Count and Compare},label=ana4,index={anagramSolution4},float=htb]
def anagramSolution4(s1,s2):
    c1 = [0]*26
    c2 = [0]*26

    for i in range(len(s1)):
        pos = ord(s1[i])-ord('a')
        c1[pos] = c1[pos] + 1

    for i in range(len(s2)):
        pos = ord(s2[i])-ord('a')
        c2[pos] = c2[pos] + 1

    j = 0
    stillOK = True
    while j&lt;26 and stillOK:
        if c1[j]==c2[j]:
            j = j + 1
        else:
            stillOK = False

    return stillOK</pre>
</div>
<p>{}</p>
<p>Again, the solution has a number of iterations. However, unlike the
first solution, none of them are nested. The first two iterations used
to count the characters are both based on <em>n</em>. The third iteration,
comparing the two lists of counts, always takes 26 steps since there are
26 possible characters in the strings. Adding it all up gives us
<span class="math">\(T(n)=2n+26\)</span> steps. That is <span class="math">\(O(n)\)</span>. We have found a
linear order of magnitude algorithm for solving this problem.</p>
<p>Before leaving this example, we need to say something about space
requirements. Although the last solution was able to run in linear time,
it could only do so by using additional storage to keep the two lists of
character counts. In other words, this algorithm sacrificed space in
order to gain time.</p>
<p>This is a common occurrence. On many occasions you will need to make
decisions between time and space trade-offs. In this case, the amount of
extra space is not significant. However, if the underlying alphabet had
millions of characters, there would be more concern. As a computer
scientist, when given a choice of algorithms, it will be up to you to
determine the best use of computing resources given a particular
problem.</p>
</div>
</div>
</div>
<div class="section" id="performance-of-python-data-structures">
<h2>Performance of Python Data Structures<a class="headerlink" href="#performance-of-python-data-structures" title="Permalink to this headline">¶</a></h2>
<p>{sec:perf-pyth-data} Now that you have a general idea of Big-O notation
and the differences in between the different functions, our goal in this
section is to tell you about the Big-O performance for the operations on
Python lists and dictionaries. We will then show you some timing
experiments that illustrate the costs and benefits of using certain
operations on each data structure. It is important for you to understand
the efficiency of these Python data structures because they are the
building blocks we will use as we implement other data structures in the
remainder of the book. In this section we are not going to explain why
the performance is what it is. In later chapters you will see some
possible implementations of both lists and dictionaries and how the
performance depends on the implementation.</p>
<div class="section" id="lists">
<h3>Lists<a class="headerlink" href="#lists" title="Permalink to this headline">¶</a></h3>
<p>{sec:lists}</p>
<p>The designers of Python had many choices to make when they implemented
the list data structure. Each of these choices could have an impact on
how fast list operations perform. To help them make the right choices
they looked at the ways that people would most commonly use the list
data structure and they optimized their implementation of a list so that
the most common operations were very fast. Of course they also tried to
make the less common operations fast, but when a tradeoff had to be made
the performance of a less common operation was often sacrificed in favor
of the more common operation.</p>
<p>Two common operations are indexing and assigning to an index position.
Both of these operations take the same amount of time no matter how
large the list becomes. When an operation like this is independent of
the size of the list they are <span class="math">\(O(1)\)</span>.</p>
<p>Another very common programming task is to grow a list. There are two
ways to create a longer list either using the append method, or the
concatenation operator. The append method is <span class="math">\(O(1)\)</span>. However,
the concatenation operator is <span class="math">\(O(k)\)</span> where <span class="math">\(k\)</span> is the
size of the list that is being concatenated. This is important for you
to know because it can help you make your own programs more efficient by
choosing the right tool for the job.</p>
<p>Lets look at four different ways we might generate a list of <tt class="docutils literal"><span class="pre">n</span></tt>
numbers starting with 0. First we’ll try a <tt class="docutils literal"><span class="pre">for</span></tt> loop and create the
list by concatenation, then we’ll use append rather than concatenation.
Next, we’ll try creating the list using list comprehension and finally,
and perhaps the most obvious way, using the range function wrapped by a
call to the list constructor. Listing&nbsp;{lst:mklist} shows the code for
making our list four different ways. In the remainder of this section we
will assume this code is saved in the file <tt class="docutils literal"><span class="pre">listfuns.py</span></tt>.</p>
<div class="highlight-python"><pre>[caption={Four Ways to Make a List},label=lst:mklist,index={list performance},float=htb]
def test1():
    l = []
    for i in range(1000):
        l = l + [i]

def test2():
    l = []
    for i in range(1000):
        l.append(i)

def test3():
    l = [i for i in range(1000)]

def test4():
    l = list(range(1000))</pre>
</div>
<p>To capture the time it takes for each of our functions to execute we
will use Python’s <tt class="docutils literal"><span class="pre">timeit</span></tt> module. The <tt class="docutils literal"><span class="pre">timeit</span></tt> module is designed
to allow Python developers to make cross-platform timing measurements by
running functions in a consistent environment and using timing
mechanisms that are as similar as possible across operating systems.</p>
<p>To use <tt class="docutils literal"><span class="pre">timeit</span></tt> you create a <tt class="docutils literal"><span class="pre">Timer</span></tt> object whose parameters are two
Python statements. The first parameter is a Python statement that you
want to time; the second parameter is a statement that will run once to
set up the test. The <tt class="docutils literal"><span class="pre">timeit</span></tt> module will then time how long it takes
to execute the statement some number of times. By default <tt class="docutils literal"><span class="pre">timeit</span></tt>
will try to run the statement one million times. When its done it
returns the time as a floating point value representing the total number
of seconds. However, since it executes the statement a million times you
can read the result as the number of microseconds to execute the test
one time. You can also pass <tt class="docutils literal"><span class="pre">timeit</span></tt> a named parameter called
<tt class="docutils literal"><span class="pre">number</span></tt> that allows you to specify how many times the test statement
is executed. The following session shows how long it takes to run each
of our test functions 1000 times.</p>
<div class="highlight-python"><pre>t1 = Timer("test1()", "from __main__ import test1")
print("concat ",t1.timeit(number=1000), "milliseconds")
t2 = Timer("test2()", "from __main__ import test2")
print("append ",t2.timeit(number=1000), "milliseconds")
t3 = Timer("test3()", "from __main__ import test3")
print("comprehension ",t3.timeit(number=1000), "milliseconds")
t4 = Timer("test4()", "from __main__ import test4")
print("list range ",t4.timeit(number=1000), "milliseconds")

concat  6.54352807999 milliseconds
append  0.306292057037 milliseconds
comprehension  0.147661924362 milliseconds
list range  0.0655000209808 milliseconds</pre>
</div>
<p>In the experiment above the statement that we are timing is the function
call to <tt class="docutils literal"><span class="pre">test1()</span></tt>, <tt class="docutils literal"><span class="pre">test2()</span></tt>, and so on. The setup statement may
look very strange to you, so let’s consider it in more detail. You are
probably very familiar with the <tt class="docutils literal"><span class="pre">from</span></tt>, <tt class="docutils literal"><span class="pre">import</span></tt> statement, but this
is usually used at the beginning of a Python program file. In this case
the statement <tt class="docutils literal"><span class="pre">from</span> <span class="pre">__main__</span> <span class="pre">import</span> <span class="pre">test1</span></tt> imports the function
<tt class="docutils literal"><span class="pre">test1</span></tt> from the {__main__} namespace into the namespace that
<tt class="docutils literal"><span class="pre">timeit</span></tt> sets up for the timing experiment. The <tt class="docutils literal"><span class="pre">timeit</span></tt> module does
this because it wants to run the timing tests in an environment that is
uncluttered by any stray variables you may have created, that may
interfere with your function’s performance in some unforeseen way.</p>
<p>From the experiment above it is clear that the append operation at 0.30
milliseconds is much faster than concatenation at 6.54 milliseconds. In
the above experiment we also show the times for two additional methods
for creating a list; using the list constructor with a call to <tt class="docutils literal"><span class="pre">range</span></tt>
and a list comprehension. It is interesting to note that the list
comprehension is twice as fast as a <tt class="docutils literal"><span class="pre">for</span></tt> loop with an <tt class="docutils literal"><span class="pre">append</span></tt>
operation.</p>
<p>One final observation about this little experiment is that all of the
times that you see above include some overhead for actually calling the
test function, but we can assume that the function call overhead is
identical in all four cases so we still get a meaningful comparison of
the operations. So it would not be accurate to say that the
concatenation operation takes 6.54 milliseconds but rather the
concatenation test function takes 6.54 milliseconds. As an exercise you
could test the time it takes to call an empty function and subtract that
from the numbers above.</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">Operation</th>
<th class="head">Big-O Efficiency</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>index []</td>
<td>O(1)</td>
</tr>
<tr class="row-odd"><td>index assignment</td>
<td>O(1)</td>
</tr>
<tr class="row-even"><td>append</td>
<td>O(1)</td>
</tr>
<tr class="row-odd"><td>pop()</td>
<td>O(1)</td>
</tr>
<tr class="row-even"><td>pop(i)</td>
<td>O(n)</td>
</tr>
<tr class="row-odd"><td>insert(i,item)</td>
<td>O(n)</td>
</tr>
<tr class="row-even"><td>del operator</td>
<td>O(n)</td>
</tr>
<tr class="row-odd"><td>iteration</td>
<td>O(n)</td>
</tr>
<tr class="row-even"><td>contains (in)</td>
<td>O(n)</td>
</tr>
<tr class="row-odd"><td>get slice [x:y]</td>
<td>O(k)</td>
</tr>
<tr class="row-even"><td>del slice</td>
<td>O(n)</td>
</tr>
<tr class="row-odd"><td>set slice</td>
<td>O(n+k)</td>
</tr>
<tr class="row-even"><td>reverse</td>
<td>O(n)</td>
</tr>
<tr class="row-odd"><td>concatenate</td>
<td>O(k)</td>
</tr>
<tr class="row-even"><td>sort</td>
<td>O(n log n)</td>
</tr>
<tr class="row-odd"><td>multiply</td>
<td>O(nk)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>{Big-O Efficiency of Python List Operations} {tab:listbigo}</div></blockquote>
<p>Now that we have seen how performance can be measured concretely you can
look at Table&nbsp;{tab:listbigo} to see the Big-O efficiency of all the
basic list operations. After thinking carefully about
Table&nbsp;{tab:listbigo}, you may be wondering about the two different times
for <tt class="docutils literal"><span class="pre">pop</span></tt>. When <tt class="docutils literal"><span class="pre">pop</span></tt> is called on the end of the list it takes
<span class="math">\(O(1)\)</span> but when pop is called on the first element in the list
or anywhere in the middle it is <span class="math">\(O(n)\)</span>. The reason for this lies
in how Python chooses to implement lists. When an item is taken from the
front of the list, in Python’s implementation, all the other elements in
the list are shifted one position closer to the beginning. This may seem
silly to you now, but if you look at Table&nbsp;{tab:listbigo} you will see
that this implementation also allows the index operation to be
<span class="math">\(O(1)\)</span>. This is a tradeoff that the Python implementors thought
was a good one.</p>
<p>As a way of demonstrating this difference in performance let’s do
another experiment using the <tt class="docutils literal"><span class="pre">timeit</span></tt> module. Our goal is to be able
to verify the performance of the <tt class="docutils literal"><span class="pre">pop</span></tt> operation on a list of a known
size when the program pops from the end of the list, and again when the
program pops from the beginning of the list. We will also want to
measure this time for lists of different sizes. What we would expect to
see is that the time required to pop from the end of the list will stay
constant even as the list grows in size, while the time to pop from the
beginning of the list will continue to increase as the list grows.</p>
<p>Listing&nbsp;{lst:popmeas} shows one attempt to measure the difference
between the two uses of pop. As you can see from this first example
popping from the end takes 0.0003 milliseconds, whereas popping from the
beginning takes 4.82 milliseconds. For a list of two million elements
this is a factor of 16,000.</p>
<p>There are a couple of things to notice about Listing&nbsp;{lst:popmeas}. The
first is the statement <tt class="docutils literal"><span class="pre">from</span> <span class="pre">__main__</span> <span class="pre">import</span> <span class="pre">x</span></tt>. Although we did not
define a function we do want to be able to use the list object x in our
test. This approach allows us to time just the single <tt class="docutils literal"><span class="pre">pop</span></tt> statement
and get the most accurate measure of the time for that single operation.
Because the timer repeats 1000 times it is also important to point out
that the list is decreasing in size by 1 each time through the loop. But
since the initial list is two million elements in size we only reduce
the overall size by <span class="math">\(0.05\%\)</span></p>
<div class="highlight-python"><pre>[caption={Timing the Performance of \texttt{pop} },label=lst:popmeas,index={pop performance},float=htb]

popzero = timeit.Timer("x.pop(0)",
                       "from __main__ import x")
popend = timeit.Timer("x.pop()",
                      "from __main__ import x")

x = list(range(2000000))
popzero.timeit(number=1000)
4.8213560581207275

x = list(range(2000000))
popend.timeit(number=1000)
0.0003161430358886719</pre>
</div>
<p>While our first test does show that <tt class="docutils literal"><span class="pre">pop(0)</span></tt> is indeed slower than
<tt class="docutils literal"><span class="pre">pop()</span></tt>, it does not validate the claim that <tt class="docutils literal"><span class="pre">pop(0)</span></tt> is
<span class="math">\(O(n)\)</span> while <tt class="docutils literal"><span class="pre">pop()</span></tt> is <span class="math">\(O(1)\)</span>. To validate that claim
we need to look at the performance of both calls over a range of list
sizes. Listing&nbsp;{lst:poplists} implements this test.</p>
<div class="highlight-python"><pre>[caption={Comparing Performance of \texttt{pop} for Different
  List Sizes},label=lst:poplists,index={pop performance},float=htb]

popzero = Timer("x.pop(0)",
                "from __main__ import x")
popend = Timer("x.pop()",
               "from __main__ import x")
print("pop(0)   pop()")
for i in range(1000000,100000001,1000000):
    x = list(range(i))
    pt = popend.timeit(number=1000)
    x = list(range(i))
    pz = popzero.timeit(number=1000)
    print("%15.5f, %15.5f" %(pz,pt))</pre>
</div>
<p>Figure&nbsp;{fig:poptest} shows the results of our experiment. You can see
that as the list gets longer and longer the time it takes to <tt class="docutils literal"><span class="pre">pop(0)</span></tt>
also increases while the time for <tt class="docutils literal"><span class="pre">pop</span></tt> stays very flat. This is
exactly what we would expect to see for a <span class="math">\(O(n)\)</span> and
<span class="math">\(O(1)\)</span> algorithm.</p>
<p>Some sources of error in our little experiment include the fact that
there are other processes running on the computer as we measure that may
slow down our code, so even though we try to minimize other things
happening on the computer there is bound to be some variation in time.
That is why the loop runs the test one thousand times in the first place
to statistically gather enough information to make the measurement
reliable.</p>
<blockquote>
<div><img alt="image2" src="_images/poptime.png" /> {Comparing the Performance of <tt class="docutils literal"><span class="pre">pop</span></tt> and <tt class="docutils literal"><span class="pre">pop(0)</span></tt>}
{fig:poptest}</div></blockquote>
</div>
<div class="section" id="dictionaries">
<h3>Dictionaries<a class="headerlink" href="#dictionaries" title="Permalink to this headline">¶</a></h3>
<p>{sec:dictionaries}</p>
<p>The second major Python data structure is the dictionary. As you
probably recall, dictionaries differ from lists in that you can access
items in a dictionary by a key rather than a position. Later in this
book you will see that there are many ways to implement a dictionary.
The thing that is most important to notice right now is that the get
item and set item operations on a dictionary are <span class="math">\(O(1)\)</span>. Another
important dictionary operation is the contains operation. Checking to
see whether a key is in the dictionary or not is also <span class="math">\(O(1)\)</span>.
The efficiency of all dictionary operations is summarized in
Table&nbsp;{tab:dictbigo}. One important side note on dictionary performance
is that the efficiencies we provide in the table are for average
performance. In some rare cases the contains, get item, and set item
operations can degenerate into <span class="math">\(O(n)\)</span> performance but we will
get into that in a later chapter when we talk about the different ways
that a dictionary could be implemented.</p>
<table border="1" class="docutils">
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead valign="bottom">
<tr class="row-odd"><th class="head">operation</th>
<th class="head">Big-O Efficiency</th>
</tr>
</thead>
<tbody valign="top">
<tr class="row-even"><td>copy</td>
<td>O(n)</td>
</tr>
<tr class="row-odd"><td>get item</td>
<td>O(1)</td>
</tr>
<tr class="row-even"><td>set item</td>
<td>O(1)</td>
</tr>
<tr class="row-odd"><td>delete item</td>
<td>O(1)</td>
</tr>
<tr class="row-even"><td>contains (in)</td>
<td>O(1)</td>
</tr>
<tr class="row-odd"><td>iteration</td>
<td>O(n)</td>
</tr>
</tbody>
</table>
<blockquote>
<div>{Big-O Efficiency of Python Dictionary Operations} {tab:dictbigo}</div></blockquote>
<p>For our last performance experiment we will compare the performance of
the contains operation between lists and dictionaries. In the process we
will confirm that the contains operator for lists is <span class="math">\(O(n)\)</span> and
the contains operator for dictionaries is <span class="math">\(O(1)\)</span>. The experiment
we will use to compare the two is simple. We’ll make a list with a range
of numbers in it. Then we will pick numbers at random and check to see
if the numbers are in the list. If our performance tables are correct
the bigger the list the longer it should take to determine if any one
number is contained in the list.</p>
<p>We will repeat the same experiment for a dictionary that contains
numbers as the keys. In this experiment we should see that determining
whether or not a number is in the dictionary is not only much faster,
but the time it takes to check should remain constant even as the
dictionary grows larger.</p>
<p>Listing&nbsp;{lst:listvdict} implements this comparison. Notice that we are
performing exactly the same operation, {number in container}. The
difference is that on line 7 <tt class="docutils literal"><span class="pre">x</span></tt> is a list, and on line 9 <tt class="docutils literal"><span class="pre">x</span></tt> is a
dictionary.</p>
<div class="highlight-python"><pre>[caption={Comparing Performance of Contains for List
    and Dictionary},label=lst:listvdict,index={dictionary performance},float=htb]
import timeit
import random

for i in range(10000,1000001,20000):
    t = timeit.Timer("random.randrange(%d) in x"%i,
                     "from __main__ import random,x")
    x = list(range(i))
    lst_time = t.timeit(number=1000)
    x = {j:None for j in range(i)}
    d_time = t.timeit(number=1000)
    print("%d,%10.3f,%10.3f" % (i, lst_time, d_time))</pre>
</div>
<p>Figure&nbsp;{fig:listvdict} summarizes the results of running
Listing&nbsp;{lst:listvdict}. You can see that the dictionary is consistently
faster. For the smallest list size of 10,000 elements a dictionary is
89.4 times faster than a list. For the largest list size of 990,000
elements the dictionary is 11,603 times faster! You can also see that
the time it takes for the contains operator on the list grows linearly
with the size of the list. This verifies the assertion that the contains
operator on a list is <span class="math">\(O(n)\)</span>. It can also be seen that the time
for the contains operator on a dictionary is constant even as the
dictionary size grows. In fact for a dictionary size of 10,000 the
contains operation took 0.004 milliseconds and for the dictionary size
of 990,000 it also took 0.004 milliseconds.</p>
<blockquote>
<div><img alt="image3" src="_images/listvdict.png" /> {Comparing the <tt class="docutils literal"><span class="pre">in</span></tt> Operator for Python Lists and
Dictionaries} {fig:listvdict}</div></blockquote>
<p>Since Python is an evolving language, there are always changes going on
behind the scenes. The latest information on the performance of Python
data structures can be found on the Python website. As of this writing
the Python wiki has a nice time complexity page that can be found at
<tt class="docutils literal"><span class="pre">http://wiki.python.org/moin/TimeComplexity</span></tt>.</p>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>Algorithm analysis is an implementation-independent way of measuring
an algorithm.</li>
<li>Big-O notation allows algorithms to be classified by their dominant
process with respect to the size of the problem.</li>
</ul>
</div>
<div class="section" id="key-terms">
<h2>Key Terms<a class="headerlink" href="#key-terms" title="Permalink to this headline">¶</a></h2>
<table border="1" class="docutils">
<colgroup>
<col width="41%" />
<col width="26%" />
<col width="33%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>average case</td>
<td>Big-O notation</td>
<td>brute force</td>
</tr>
<tr class="row-even"><td>checking off</td>
<td>exponential</td>
<td>linear</td>
</tr>
<tr class="row-odd"><td>log linear</td>
<td>logarithmic</td>
<td>order of magnitude</td>
</tr>
<tr class="row-even"><td>quadratic</td>
<td>time complexity</td>
<td>worst case</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="discussion-questions">
<h2>Discussion Questions<a class="headerlink" href="#discussion-questions" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first">Give the Big-O performance of the following code fragment:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
   <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
      <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span>
</pre></div>
</div>
</li>
<li><p class="first">Give the Big-O performance of the following code fragment:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
     <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span>
</pre></div>
</div>
</li>
<li><p class="first">Give the Big-O performance of the following code fragment:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">i</span> <span class="o">=</span> <span class="n">n</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
   <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span>
   <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="mi">2</span>
</pre></div>
</div>
</li>
<li><p class="first">Give the Big-O performance of the following code fragment:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
   <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
         <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span>
</pre></div>
</div>
</li>
<li><p class="first">Give the Big-O performance of the following code fragment:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">i</span> <span class="o">=</span> <span class="n">n</span>
<span class="k">while</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
   <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span>
   <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="mi">2</span>
</pre></div>
</div>
</li>
<li><p class="first">Give the Big-O performance of the following code fragment:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
   <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
   <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
   <span class="n">k</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="mi">2</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="programming-exercises">
<h2>Programming Exercises<a class="headerlink" href="#programming-exercises" title="Permalink to this headline">¶</a></h2>
<p>{sec:exercises}</p>
<ol class="arabic simple">
<li>Devise an experiment to verify that the list index operator is
<span class="math">\(O(1)\)</span></li>
<li>Devise an experiment to verify that get item and set item are
<span class="math">\(O(1)\)</span> for dictionaries.</li>
<li>Devise an experiment that compares the performance of the <tt class="docutils literal"><span class="pre">del</span></tt>
operator on lists and dictionaries.</li>
<li>Given a list of numbers in random order write a linear time algorithm
to find the kth smallest number in the list. Explain why your
algorithm is linear.</li>
<li>Can you improve the algorithm from the previous problem to be
<span class="math">\(On\log(n)\)</span>?</li>
</ol>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="basic.html" title="Basic Data Structures"
             >next</a> |</li>
        <li class="right" >
          <a href="introduction.html" title="Introduction"
             >previous</a> |</li>
        <li><a href="index.html">Problem Solving with Algorithms and Data Structures 3.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011, Brad Miller, Kent Lee, David Ranum.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2pre.
    </div>
  </body>
</html>