

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Searching and Sorting &mdash; Problem Solving with Algorithms and Data Structures 3.0 documentation</title>
    
    <link rel="stylesheet" href="_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/video.css" type="text/css" />
    <link rel="stylesheet" href="_static/edu-python.css" type="text/css" />
    <link rel="stylesheet" href="_static/codemirror.css" type="text/css" />
    <link rel="stylesheet" href="_static/theme/default.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/simplemodal.js"></script>
    <script type="text/javascript" src="_static/jquery.textarea.js"></script>
    <script type="text/javascript" src="_static/edu-python.js"></script>
    <script type="text/javascript" src="_static/bookfuncs.js"></script>
    <script type="text/javascript" src="_static/codemirror.js"></script>
    <script type="text/javascript" src="_static/python.js"></script>
    <script type="text/javascript" src="_static/skulpt.js"></script>
    <script type="text/javascript" src="_static/builtin.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="Problem Solving with Algorithms and Data Structures 3.0 documentation" href="index.html" />
    <link rel="next" title="Trees" href="trees.html" />
    <link rel="prev" title="Recursion" href="recursion.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="trees.html" title="Trees"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="recursion.html" title="Recursion"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">Problem Solving with Algorithms and Data Structures 3.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Searching and Sorting</a><ul>
<li><a class="reference internal" href="#objectives">Objectives</a></li>
<li><a class="reference internal" href="#searching">Searching</a><ul>
<li><a class="reference internal" href="#the-sequential-search">The Sequential Search</a><ul>
<li><a class="reference internal" href="#analysis-of-sequential-search">Analysis of Sequential Search</a></li>
</ul>
</li>
<li><a class="reference internal" href="#the-binary-search">The Binary Search</a><ul>
<li><a class="reference internal" href="#analysis-of-binary-search">Analysis of Binary Search</a></li>
</ul>
</li>
<li><a class="reference internal" href="#hashing">Hashing</a><ul>
<li><a class="reference internal" href="#hash-functions">Hash Functions</a></li>
<li><a class="reference internal" href="#collision-resolution">Collision Resolution</a></li>
<li><a class="reference internal" href="#implementing-the-map-abstract-data-type">Implementing the <tt class="docutils literal"><span class="pre">Map</span></tt> Abstract Data Type</a></li>
<li><a class="reference internal" href="#analysis-of-hashing">Analysis of Hashing</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#sorting">Sorting</a><ul>
<li><a class="reference internal" href="#the-bubble-sort">The Bubble Sort</a></li>
<li><a class="reference internal" href="#the-selection-sort">The Selection Sort</a></li>
<li><a class="reference internal" href="#the-insertion-sort">The Insertion Sort</a></li>
<li><a class="reference internal" href="#the-shell-sort">The Shell Sort</a></li>
<li><a class="reference internal" href="#the-merge-sort">The Merge Sort</a></li>
<li><a class="reference internal" href="#the-quick-sort">The Quick Sort</a></li>
</ul>
</li>
<li><a class="reference internal" href="#summary">Summary</a></li>
<li><a class="reference internal" href="#key-terms">Key Terms</a></li>
<li><a class="reference internal" href="#discussion-questions">Discussion Questions</a></li>
<li><a class="reference internal" href="#programming-exercises">Programming Exercises</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="recursion.html"
                        title="previous chapter">Recursion</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="trees.html"
                        title="next chapter">Trees</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/sortsearch.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="searching-and-sorting">
<h1>Searching and Sorting<a class="headerlink" href="#searching-and-sorting" title="Permalink to this headline">¶</a></h1>
<p>{chap:sortsearch}</p>
<div class="section" id="objectives">
<h2>Objectives<a class="headerlink" href="#objectives" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>To be able to explain and implement sequential search and binary
search.</li>
<li>To be able to explain and implement selection sort, bubble sort,
merge sort, quick sort, insertion sort, and shell sort.</li>
<li>To understand the idea of hashing as a search technique.</li>
<li>To introduce the map abstract data type.</li>
<li>To implement the map abstract data type using hashing.</li>
</ul>
</div>
<div class="section" id="searching">
<h2>Searching<a class="headerlink" href="#searching" title="Permalink to this headline">¶</a></h2>
<p>We will now turn our attention to some of the most common problems that
arise in computing, those of searching and sorting. In this section we
will study searching. We will return to sorting later in the chapter.
Searching is the algorithmic process of finding a particular item in a
collection of items. A search typically answers either <tt class="docutils literal"><span class="pre">True</span></tt> or
<tt class="docutils literal"><span class="pre">False</span></tt> as to whether the item is present. On occasion it may be
modified to return where the item is found. For our purposes here, we
will simply concern ourselves with the question of membership.</p>
<p>In Python, there is a very easy way to ask whether an item is in a list
of items. We use the <tt class="docutils literal"><span class="pre">in</span></tt> operator.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="mi">15</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="mi">3</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>
<span class="go">True</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
<p>Even though this is easy to write, an underlying process must be carried
out to answer the question. It turns out that there are many different
ways to search for the item. What we are interested in here is how these
algorithms work and how they compare to one another.</p>
<div class="section" id="the-sequential-search">
<h3>The Sequential Search<a class="headerlink" href="#the-sequential-search" title="Permalink to this headline">¶</a></h3>
<p>When data items are stored in a collection such as a list, we say that
they have a linear or sequential relationship. Each data item is stored
in a position relative to the others. In Python lists, these relative
positions are the index values of the individual items. Since these
index values are ordered, it is possible for us to visit them in
sequence. This process gives rise to our first searching technique, the
<strong>sequential search</strong>.</p>
<p>Figure&nbsp;{seqsearch} shows how this search works. Starting at the first
item in the list, we simply move from item to item, following the
underlying sequential ordering until we either find what we are looking
for or run out of items. If we run out of items, we have discovered that
the item we were searching for was not present.</p>
<blockquote>
<div><img alt="image" src="_images/seqsearch.png" /> {Sequential Search of a List of Integers} {seqsearch}</div></blockquote>
<p>The Python implementation for this algorithm is shown in
Listing&nbsp;{seqsearchpython}. The function needs the list and the item we
are looking for and returns a boolean value as to whether it is present.
The boolean variable <tt class="docutils literal"><span class="pre">found</span></tt> is initialized to <tt class="docutils literal"><span class="pre">False</span></tt> and is
assigned the value <tt class="docutils literal"><span class="pre">True</span></tt> if we discover the item in the list.</p>
<div class="highlight-python"><pre>[caption={Sequential Search of an Unordered List},label=seqsearchpython,index={sequentialSearch},float=htb]
def sequentialSearch(alist, item):
    pos = 0
    found = False

    while pos &lt; len(alist) and not found:
        if alist[pos] == item:
            found = True
        else:
            pos = pos+1

    return found</pre>
</div>
<div class="section" id="analysis-of-sequential-search">
<h4>Analysis of Sequential Search<a class="headerlink" href="#analysis-of-sequential-search" title="Permalink to this headline">¶</a></h4>
<p>To analyze searching algorithms, we need to decide on a basic unit of
computation. Recall that this is typically the common step that must be
repeated in order to solve the problem. For searching, it makes sense to
count the number of comparisons performed. Each comparison may or may
not discover the item we are looking for. In addition, we make another
assumption here. The list of items is not ordered in any way. The items
have been placed randomly into the list. In other words, the probability
that the item we are looking for is in any particular position is
exactly the same for each position of the list.</p>
<p>If the item is not in the list, the only way to know it is to compare it
against every item present. If there are <span class="math">\(n\)</span> items, then the
sequential search requires <span class="math">\(n\)</span> comparisons to discover that the
item is not there. In the case where the item is in the list, the
analysis is not so straightforward. There are actually three different
scenarios that can occur. In the best case we will find the item in the
first place we look, at the beginning of the list. We will need only one
comparison. In the worst case, we will not discover the item until the
very last comparison, the n``th`` comparison.</p>
<p>What about the average case? On average, we will find the item about
halfway into the list; that is, we will compare against
<span class="math">\(\frac{n}{2}\)</span> items. Recall, however, that as <em>n</em> gets large,
the coefficients, no matter what they are, become insignificant in our
approximation, so the complexity of the sequential search, is
<span class="math">\(O(n)\)</span>. Table&nbsp;{seqsearchtable} summarizes these results.</p>
<blockquote>
<div><blockquote>
<div><dl class="docutils">
<dt>&amp; <strong>Best Case</strong> &amp; <strong>Worst Case</strong> &amp; <strong>Average Case</strong></dt>
<dd>[-1.25ex] {0cm} {3.5ex} item is present &amp; <span class="math">\(1\)</span> &amp;</dd>
<dt><span class="math">\(n\)</span> &amp; <span class="math">\(\frac{n}{2}\)</span></dt>
<dd>[-1.25ex] {0cm} {3.5ex} item is not present &amp; <span class="math">\(n\)</span> &amp;</dd>
</dl>
<p><span class="math">\(n\)</span> &amp; <span class="math">\(n\)</span></p>
</div></blockquote>
<p>{Comparisons Used in a Sequential Search of an Unordered List}
{seqsearchtable}</p>
</div></blockquote>
<p>We assumed earlier that the items in our collection had been randomly
placed so that there is no relative order between the items. What would
happen to the sequential search if the items were ordered in some way?
Would we be able to gain any efficiency in our search technique?</p>
<p>Assume that the list of items was constructed so that the items were in
ascending order, from low to high. If the item we are looking for is
present in the list, the chance of it being in any one of the <em>n</em>
positions is still the same as before. We will still have the same
number of comparisons to find the item. However, if the item is not
present there is a slight advantage. Figure&nbsp;{seqsearch2} shows this
process as the algorithm looks for the item 50. Notice that items are
still compared in sequence until 54. At this point, however, we know
something extra. Not only is 54 not the item we are looking for, but no
other elements beyond 54 can work either since the list is sorted. In
this case, the algorithm does not have to continue looking through all
of the items to report that the item was not found. It can stop
immediately. Listing&nbsp;{seqsearchpython2} shows this variation of the
sequential search function.</p>
<blockquote>
<div><img alt="image1" src="_images/seqsearch2.png" /> {Sequential Search of an Ordered List of Integers}
{seqsearch2}</div></blockquote>
<div class="highlight-python"><pre>[caption={Sequential Search of an Ordered List},label=seqsearchpython2,index={orderedSequentialSearch},float=htb]
def orderedSequentialSearch(alist, item):
    pos = 0
    found = False
    stop = False
    while pos &lt; len(alist) and not found and not stop:
        if alist[pos] == item:
            found = True
        else:
            if alist[pos] &gt; item:
                stop = True
            else:
                pos = pos+1

    return found</pre>
</div>
<p>Table&nbsp;{seqsearchtable2} summarizes these results. Note that in the best
case we might discover that the item is not in the list by looking at
only one item. On average, we will know after looking through only
<span class="math">\(\frac {n}{2}\)</span> items. However, this technique is still
<span class="math">\(O(n)\)</span>. In summary, a sequential search is improved by ordering
the list only in the case where we do not find the item.</p>
<blockquote>
<div><blockquote>
<div><dl class="docutils">
<dt>&amp; <strong>Best Case</strong> &amp; <strong>Worst Case</strong> &amp; <strong>Average Case</strong></dt>
<dd>[-1.25ex] {0cm} {3.5ex} item is present &amp; <span class="math">\(1\)</span> &amp;</dd>
<dt><span class="math">\(n\)</span> &amp; <span class="math">\(\frac{n}{2}\)</span></dt>
<dd>[-1.25ex] {0cm} {3.5ex} item is not present &amp; <span class="math">\(1\)</span> &amp;</dd>
</dl>
<p><span class="math">\(n\)</span> &amp; <span class="math">\(\frac{n}{2}\)</span></p>
</div></blockquote>
<p>{Comparisons Used in Sequential Search of an Ordered List}
{seqsearchtable2}</p>
</div></blockquote>
</div>
</div>
<div class="section" id="the-binary-search">
<h3>The Binary Search<a class="headerlink" href="#the-binary-search" title="Permalink to this headline">¶</a></h3>
<p>It is possible to take greater advantage of the ordered list if we are
clever with our comparisons. In the sequential search, when we compare
against the first item, there are at most <span class="math">\(n-1\)</span> more items to
look through if the first item is not what we are looking for. Instead
of searching the list in sequence, a <strong>binary search</strong> will start by
examining the middle item. If that item is the one we are searching for,
we are done. If it is not the correct item, we can use the ordered
nature of the list to eliminate half of the remaining items. If the item
we are searching for is greater than the middle item, we know that the
entire lower half of the list as well as the middle item can be
eliminated from further consideration. The item, if it is in the list,
must be in the upper half.</p>
<p>We can then repeat the process with the upper half. Start at the middle
item and compare it against what we are looking for. Again, we either
find it or split the list in half, therefore eliminating another large
part of our possible search space. Figure&nbsp;{binsearch} shows how this
algorithm can quickly find the value 54. The complete function is shown
in Listing&nbsp;{binarysearchpy}.</p>
<blockquote>
<div><img alt="image2" src="_images/binsearch.png" /> {Binary Search of an Ordered List of Integers} {binsearch}</div></blockquote>
<div class="highlight-python"><pre>[caption={Binary Search of an Ordered List},label=binarysearchpy,index={binarySearch},float=htb]
def binarySearch(alist, item):
    first = 0
    last = len(alist)-1
    found = False

    while first&lt;=last and not found:
        midpoint = (first + last)//2
        if alist[midpoint] == item:
            found = True
        else:
            if item &lt; alist[midpoint]:
                last = midpoint-1
            else:
                first = midpoint+1

    return found</pre>
</div>
<p>Before we move on to the analysis, we should note that this algorithm is
a great example of a divide and conquer strategy. Divide and conquer
means that we divide the problem into smaller pieces, solve the smaller
pieces in some way, and then reassemble the whole problem to get the
result. When we perform a binary search of a list, we first check the
middle item. If the item we are searching for is less than the middle
item, we can simply perform a binary search of the left half of the
original list. Likewise, if the item is greater, we can perform a binary
search of the right half. Either way, this is a recursive call to the
binary search function passing a smaller list. Listing&nbsp;{recbinarysearch}
shows this recursive version.</p>
<div class="highlight-python"><pre>[caption={A Binary Search--Recursive Version},label=recbinarysearch,index={binarySearch},float=htb]
def binarySearch(alist, item):
    if len(alist) == 0:
        return False
    else:
        midpoint = len(alist)//2
        if alist[midpoint]==item:
          return True
        else:
          if item&lt;alist[midpoint]:
            return binarySearch(alist[:midpoint],item)
          else:
            return binarySearch(alist[midpoint+1:],item)</pre>
</div>
<div class="section" id="analysis-of-binary-search">
<h4>Analysis of Binary Search<a class="headerlink" href="#analysis-of-binary-search" title="Permalink to this headline">¶</a></h4>
<p>To analyze the binary search algorithm, we need to recall that each
comparison eliminates about half of the remaining items from
consideration. What is the maximum number of comparisons this algorithm
will require to check the entire list? If we start with <em>n</em> items, about
<span class="math">\(\frac{n}{2}\)</span> items will be left after the first comparison.
After the second comparison, there will be about <span class="math">\(\frac{n}{4}\)</span>.
Then <span class="math">\(\frac{n}{8}\)</span>, <span class="math">\(\frac{n}{16}\)</span>, and so on. How many
times can we split the list? Table&nbsp;{binaryanalysis} helps us to see the
answer.</p>
<blockquote>
<div><blockquote>
<div><dl class="docutils">
<dt><strong>Comparisons</strong> &amp; <strong>Approximate Number of Items Left</strong></dt>
<dd>[-1.25ex] {0cm} {3.5ex} 1 &amp; <span class="math">\(\frac {n}{2}\)</span>
[-1.25ex] {0cm} {3.5ex} 2 &amp; <span class="math">\(\frac {n}{4}\)</span>
[-1.25ex] {0cm} {3.5ex} 3 &amp; <span class="math">\(\frac {n}{8}\)</span>
[-1.25ex] {0cm} {3.5ex}... &amp;
[-1.25ex] {0cm} {3.5ex} i &amp; <span class="math">\(\frac {n}{2^i}\)</span></dd>
</dl>
</div></blockquote>
<p>{Tabular Analysis for a Binary Search} {binaryanalysis}</p>
</div></blockquote>
<p>When we split the list enough times, we end up with a list that has just
one item. Either that is the item we are looking for or it is not.
Either way, we are done. The number of comparisons necessary to get to
this point is <em>i</em> where <span class="math">\(\frac {n}{2^i} =1\)</span>. Solving for <em>i</em>
gives us <span class="math">\(i=\log n\)</span>. The maximum number of comparisons is
logarithmic with respect to the number of items in the list. Therefore,
the binary search is <span class="math">\(O(\log n)\)</span>.</p>
<p>One additional analysis issue needs to be addressed. In the recursive
solution shown above, the recursive call,</p>
<p><tt class="docutils literal"><span class="pre">binarySearch(alist[:midpoint],item)</span></tt></p>
<p>uses the slice operator to create the left half of the list that is then
passed to the next invocation (similarly for the right half as well).
The analysis that we did above assumed that the slice operator takes
constant time. However, we know that the slice operator in Python is
actually O(k). This means that the binary search using slice will not
perform in strict logarithmic time. Luckily this can be remedied by
passing the list along with the starting and ending indices. The indices
can be calculated as we did in Listing&nbsp;{binarysearchpy}. We leave this
implementation as an exercise.</p>
<p>Even though a binary search is generally better than a sequential
search, it is important to note that for small values of <em>n</em>, the
additional cost of sorting is probably not worth it. In fact, we should
always consider whether it is cost effective to take on the extra work
of sorting to gain searching benefits. If we can sort once and then
search many times, the cost of the sort is not so significant. However,
for large lists, sorting even once can be so expensive that simply
performing a sequential search from the start may be the best choice.</p>
</div>
</div>
<div class="section" id="hashing">
<h3>Hashing<a class="headerlink" href="#hashing" title="Permalink to this headline">¶</a></h3>
<p>In previous sections we were able to make improvements in our search
algorithms by taking advantage of information about where items are
stored in the collection with respect to one another. For example, by
knowing that a list was ordered, we could search in logarithmic time
using a binary search. In this section we will attempt to go one step
further by building a data structure that can be searched in
<span class="math">\(O(1)\)</span> time. This concept is referred to as <strong>hashing</strong>.</p>
<p>In order to do this, we will need to know even more about where the
items might be when we go to look for them in the collection. If every
item is where it should be, then the search can use a single comparison
to discover the presence of an item. We will see, however, that this is
typically not the case.</p>
<p>A <strong>hash table</strong> is a collection of items which are stored in such a way
as to make it easy to find them later. Each position of the hash table,
often called a <strong>slot</strong>, can hold an item and is named by an integer
value starting at 0. For example, we will have a slot named 0, a slot
named 1, a slot named 2, and so on. Initially, the hash table contains
no items so every slot is empty. We can implement a hash table by using
a list with each element initialized to the special Python value
<tt class="docutils literal"><span class="pre">None</span></tt>. Figure&nbsp;{hashtable1} shows a hash table of size <span class="math">\(m=11\)</span>.
In other words, there are <em>m</em> slots in the table, named 0 through 10.</p>
<blockquote>
<div><img alt="image3" src="_images/hashtable.png" /> {Hash Table with 11 Empty Slots} {hashtable1}</div></blockquote>
<p>The mapping between an item and the slot where that item belongs in the
hash table is called the <strong>hash function</strong>. The hash function will take
any item in the collection and return an integer in the range of slot
names, between 0 and <em>m</em>-1. Assume that we have the set of integer items
54, 26, 93, 17, 77, and 31. Our first hash function, sometimes referred
to as the “remainder method,” simply takes an item and divides it by the
table size, returning the remainder as its hash value
(<span class="math">\(h(item)=item \% 11\)</span>). Table&nbsp;{hashvalues1} gives all of the
hash values for our example items. Note that this remainder method
(modulo arithmetic) will typically be present in some form in all hash
functions, since the result must be in the range of slot names.</p>
<blockquote>
<div><blockquote>
<div><dl class="docutils">
<dt><strong>Item</strong> &amp; <strong>Hash Value</strong></dt>
<dd>54 &amp; 10
26 &amp; 4
93 &amp; 5
17 &amp; 6
77 &amp; 0
31 &amp; 9</dd>
</dl>
</div></blockquote>
<p>{Simple Hash Function Using Remainders} {hashvalues1}</p>
</div></blockquote>
<p>Once the hash values have been computed, we can insert each item into
the hash table at the designated position as shown in
Figure&nbsp;{hashtable2}. Note that 6 of the 11 slots are now occupied. This
is referred to as the <strong>load factor</strong>, and is commonly denoted by
<span class="math">\(\lambda = \frac {numberofitems}{tablesize}\)</span>. For this example,
<span class="math">\(\lambda = \frac {6}{11}\)</span>.</p>
<blockquote>
<div><img alt="image4" src="_images/hashtable2.png" /> {Hash Table with Six Items} {hashtable2}</div></blockquote>
<p>Now when we want to search for an item, we simply use the hash function
to compute the slot name for the item and then check the hash table to
see if it is present. This searching operation is <span class="math">\(O(1)\)</span>, since
a constant amount of time is required to compute the hash value and then
index the hash table at that location. If everything is where it should
be, we have found a constant time search algorithm.</p>
<p>You can probably already see that this technique is going to work only
if each item maps to a unique location in the hash table. For example,
if the item 44 had been the next item in our collection, it would have a
hash value of 0 (<span class="math">\(44 \% 11 == 0\)</span>). Since 77 also had a hash
value of 0, we would have a problem. According to the hash function, two
or more items would need to be in the same slot. This is referred to as
a <strong>collision</strong> (it may also be called a “clash”). Clearly, collisions
create a problem for the hashing technique. We will discuss them in
detail later.</p>
<div class="section" id="hash-functions">
<h4>Hash Functions<a class="headerlink" href="#hash-functions" title="Permalink to this headline">¶</a></h4>
<p>Given a collection of items, a hash function that maps each item into a
unique slot is referred to as a <strong>perfect hash function</strong>. If we know
the items and the collection will never change, then it is possible to
construct a perfect hash function (refer to the exercises for more about
perfect hash functions). Unfortunately, given an arbitrary collection of
items, there is no systematic way to construct a perfect hash function.
Luckily, we do not need the hash function to be perfect to still gain
performance efficiency.</p>
<p>One way to always have a perfect hash function is to increase the size
of the hash table so that each possible value in the item range can be
accommodated. This guarantees that each item will have a unique slot.
Although this is practical for small numbers of items, it is not
feasible when the number of possible items is large. For example, if the
items were nine-digit Social Security numbers, this method would require
almost one billion slots. If we only want to store data for a class of
25 students, we will be wasting an enormous amount of memory.</p>
<p>Our goal is to create a hash function that minimizes the number of
collisions, is easy to compute, and evenly distributes the items in the
hash table. There are a number of common ways to extend the simple
remainder method. We will consider a few of them here.</p>
<p>The <strong>folding method</strong> for constructing hash functions begins by
dividing the item into equal-size pieces (the last piece may not be of
equal size). These pieces are then added together to give the resulting
hash value. For example, if our item was the phone number 436-555-4601,
we would take the digits and divide them into groups of 2
(43,65,55,46,01). After the addition, <span class="math">\(43+65+55+46+01\)</span>, we get
210. If we assume our hash table has 11 slots, then we need to perform
the extra step of dividing by 11 and keeping the remainder. In this case
<span class="math">\(210\ \%\ 11\)</span> is 1, so the phone number 436-555-4601 hashes to
slot 1. Some folding methods go one step further and reverse every other
piece before the addition. For the above example, we get
<span class="math">\(43+56+55+64+01 = 219\)</span>; :math:<a href="#id1"><span class="problematic" id="id2">`</span></a>219%11 = 10 <a href="#id3"><span class="problematic" id="id4">`</span></a>.</p>
<p>Another numerical technique for constructing a hash function is called
the <strong>mid-square method</strong>. We first square the item, and then extract
some portion of the resulting digits. For example, if the item were 44,
we would first compute <span class="math">\(44 ^{2} = 1,936\)</span>. By extracting the
middle two digits, 93, and performing the remainder step, we get 5
(<span class="math">\(93\ \%\ 11\)</span>). Table&nbsp;{hashvalues2} shows items under both the
remainder method and the mid-square method. You should verify that you
understand how these values were computed.</p>
<blockquote>
<div><blockquote>
<div><dl class="docutils">
<dt><strong>Item</strong> &amp; <strong>Remainder</strong> &amp; <strong>Mid-Square</strong></dt>
<dd>54 &amp; 10 &amp; 3
26 &amp; 4 &amp; 7
93 &amp; 5 &amp; 9
17 &amp; 6 &amp; 8
77 &amp; 0 &amp; 4
31 &amp; 9 &amp; 6</dd>
</dl>
</div></blockquote>
<p>{Comparison of Remainder and Mid-Square Methods} {hashvalues2}</p>
</div></blockquote>
<p>We can also create hash functions for character-based items such as
strings. The word “cat” can be thought of as a sequence of ordinal
values.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="nb">ord</span><span class="p">(</span><span class="s">&#39;c&#39;</span><span class="p">)</span>
<span class="go">99</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">ord</span><span class="p">(</span><span class="s">&#39;a&#39;</span><span class="p">)</span>
<span class="go">97</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">ord</span><span class="p">(</span><span class="s">&#39;t&#39;</span><span class="p">)</span>
<span class="go">116</span>
</pre></div>
</div>
<p>We can then take these three ordinal values, add them up, and use the
remainder method to get a <tt class="docutils literal"><span class="pre">hash</span></tt> value (see Figure&nbsp;{stringhash}).
Listing&nbsp;{hashfunction1} shows a function called <tt class="docutils literal"><span class="pre">hash</span></tt> that takes a
string and a table size and returns the hash value in the range from 0
to <tt class="docutils literal"><span class="pre">tablesize</span></tt>-1.</p>
<blockquote>
<div><img alt="image5" src="_images/stringhash.png" /> {Hashing a String Using Ordinal Values} {stringhash}</div></blockquote>
<div class="highlight-python"><pre>[caption={Simple Hash Function for Strings},label=hashfunction1,index={hash},float=htb]
def hash(astring, tablesize):
    sum = 0
    for pos in range(len(astring)):
        sum = sum + ord(astring[pos])

    return sum%tablesize</pre>
</div>
<p>It is interesting to note that when using this hash function, anagrams
will always be given the same hash value. To remedy this, we could use
the position of the character as a weight. Figure&nbsp;{stringhash2} shows
one possible way to use the positional value as a weighting factor. The
modification to the <tt class="docutils literal"><span class="pre">hash</span></tt> function is left as an exercise.</p>
<blockquote>
<div><img alt="image6" src="_images/stringhash2.png" /> {Hashing a String Using Ordinal Values with Weighting}
{stringhash2}</div></blockquote>
<p>You may be able to think of a number of additional ways to compute hash
values for items in a collection. The important thing to remember is
that the hash function has to be efficient so that it does not become
the dominant part of the storage and search process. If the hash
function is too complex, then it becomes more work to compute the slot
name than it would be to simply do a basic sequential or binary search
as described earlier. This would quickly defeat the purpose of hashing.</p>
</div>
<div class="section" id="collision-resolution">
<h4>Collision Resolution<a class="headerlink" href="#collision-resolution" title="Permalink to this headline">¶</a></h4>
<p>We now return to the problem of collisions. When two items hash to the
same slot, we must have a systematic method for placing the second item
in the hash table. This process is called <strong>collision resolution</strong>. As
we stated earlier, if the hash function is perfect, collisions will
never occur. However, since this is often not possible, collision
resolution becomes a very important part of hashing.</p>
<p>One method for resolving collisions looks into the hash table and tries
to find another open slot to hold the item that caused the collision. A
simple way to do this is to start at the original hash value position
and then move in a sequential manner through the slots until we
encounter the first slot that is empty. Note that we may need to go back
to the first slot (circularly) to cover the entire hash table. This
collision resolution process is referred to as <strong>open addressing</strong> in
that it tries to find the next open slot or address in the hash table.
By systematically visiting each slot one at a time, we are performing an
open addressing technique called <strong>linear probing</strong>.</p>
<p>Figure&nbsp;{linearprobing} shows an extended set of integer items under the
simple remainder method hash function (54,26,93,17,77,31,44,55,20).
Table&nbsp;{hashvalues1} above shows the hash values for the original items.
Figure&nbsp;{hashtable2} shows the original contents. When we attempt to
place 44 into slot 0, a collision occurs. Under linear probing, we look
sequentially, slot by slot, until we find an open position. In this
case, we find slot 1.</p>
<p>Again, 55 should go in slot 0 but must be placed in slot 2 since it is
the next open position. The final value of 20 hashes to slot 9. Since
slot 9 is full, we begin to do linear probing. We visit slots 10, 0, 1,
and 2, and finally find an empty slot at position 3.</p>
<blockquote>
<div><img alt="image7" src="_images/linearprobing1.png" /> {Collision Resolution with Linear Probing} {linearprobing}</div></blockquote>
<p>Once we have built a hash table using open addressing and linear
probing, it is essential that we utilize the same methods to search for
items. Assume we want to look up the item 93. When we compute the hash
value, we get 5. Looking in slot 5 reveals 93, and we can return
<tt class="docutils literal"><span class="pre">True</span></tt>. What if we are looking for 20? Now the hash value is 9, and
slot 9 is currently holding 31. We cannot simply return <tt class="docutils literal"><span class="pre">False</span></tt> since
we know that there could have been collisions. We are now forced to do a
sequential search, starting at position 10, looking until either we find
the item 20 or we find an empty slot.</p>
<p>A disadvantage to linear probing is the tendency for <strong>clustering</strong>;
items become clustered in the table. This means that if many collisions
occur at the same hash value, a number of surrounding slots will be
filled by the linear probing resolution. This will have an impact on
other items that are being inserted, as we saw when we tried to add the
item 20 above. A cluster of values hashing to 0 had to be skipped to
finally find an open position. This cluster is shown in
Figure&nbsp;{clustering}.</p>
<blockquote>
<div><img alt="image8" src="_images/clustering.png" /> {A Cluster of Items for Slot 0} {clustering}</div></blockquote>
<p>{} One way to deal with clustering is to extend the linear probing
technique so that instead of looking sequentially for the next open
slot, we skip slots, thereby more evenly distributing the items that
have caused collisions. This will potentially reduce the clustering that
occurs. Figure&nbsp;{linearprobing2} shows the items when collision
resolution is done with a “plus 3” probe. This means that once a
collision occurs, we will look at every third slot until we find one
that is empty.</p>
<blockquote>
<div><img alt="image9" src="_images/linearprobing2.png" /> {Collision Resolution Using “Plus 3”} {linearprobing2}</div></blockquote>
<p>The general name for this process of looking for another slot after a
collision is <strong>rehashing</strong>. With simple linear probing, the rehash
function is <span class="math">\(newhashvalue = rehash(oldhashvalue)\)</span> where
<span class="math">\(rehash(pos) = (pos + 1) \% sizeoftable\)</span>. The “plus 3” rehash
can be defined as <span class="math">\(rehash(pos) = (pos+3) \% sizeoftable\)</span>. In
general, <span class="math">\(rehash(pos) = (pos + skip) \% sizeoftable\)</span>. It is
important to note that the size of the “skip” must be such that all the
slots in the table will eventually be visited. Otherwise, part of the
table will be unused. To ensure this, it is often suggested that the
table size be a prime number. This is the reason we have been using 11
in our examples.</p>
<p>A variation of the linear probing idea is called <strong>quadratic probing</strong>.
Instead of using a constant “skip” value, we use a rehash function that
increments the hash value by 1, 3, 5, 7, 9, and so on. This means that
if the first hash value is <em>h</em>, the successive values are <span class="math">\(h+1\)</span>,
<span class="math">\(h+4\)</span>, <span class="math">\(h+9\)</span>, <span class="math">\(h+16\)</span>, and so on. In other words,
quadratic probing uses a skip consisting of successive perfect squares.
Figure&nbsp;{quadratic} shows our example values after they are placed using
this technique.</p>
<blockquote>
<div><img alt="image10" src="_images/quadratic.png" /> {Collision Resolution with Quadratic Probing} {quadratic}</div></blockquote>
<p>An alternative method for handling the collision problem is to allow
each slot to hold a reference to a collection (or chain) of items.
<strong>Chaining</strong> allows many items to exist at the same location in the hash
table. When collisions happen, the item is still placed in the proper
slot of the hash table. As more and more items hash to the same
location, the difficulty of searching for the item in the collection
increases. Figure&nbsp;{chaining} shows the items as they are added to a hash
table that uses chaining to resolve collisions.</p>
<blockquote>
<div><img alt="image11" src="_images/chaining.png" /> {Collision Resolution with Chaining} {chaining}</div></blockquote>
<p>When we want to search for an item, we use the hash function to generate
the slot where it should reside. Since each slot holds a collection, we
use a searching technique to decide whether the item is present. The
advantage is that on the average there are likely to be many fewer items
in each slot, so the search is perhaps more efficient. We will look at
the analysis for hashing at the end of this section.</p>
</div>
<div class="section" id="implementing-the-map-abstract-data-type">
<h4>Implementing the <tt class="docutils literal"><span class="pre">Map</span></tt> Abstract Data Type<a class="headerlink" href="#implementing-the-map-abstract-data-type" title="Permalink to this headline">¶</a></h4>
<p>One of the most useful Python collections is the dictionary. Recall that
a dictionary is an associative data type where you can store key–data
pairs. The key is used to look up the associated data value. We often
refer to this idea as a <strong>map</strong>.</p>
<p>The map abstract data type is defined as follows. The structure is an
unordered collection of associations between a key and a data value. The
keys in a map are all unique so that there is a one-to-one relationship
between a key and a value. The operations are given below.</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">Map()</span></tt> Create a new, empty map. It returns an empty map
collection.</li>
<li><tt class="docutils literal"><span class="pre">put(key,val)</span></tt> Add a new key-value pair to the map. If the key is
already in the map then replace the old value with the new value.</li>
<li><tt class="docutils literal"><span class="pre">get(key)</span></tt> Given a key, return the value stored in the map or
<tt class="docutils literal"><span class="pre">None</span></tt> otherwise.</li>
<li><tt class="docutils literal"><span class="pre">del</span></tt> Delete the key-value pair from the map using a statement of
the form <tt class="docutils literal"><span class="pre">del</span> <span class="pre">map[key]</span></tt>.</li>
<li><tt class="docutils literal"><span class="pre">len()</span></tt> Return the number of key-value pairs stored in the map.</li>
<li><tt class="docutils literal"><span class="pre">in</span></tt> Return <tt class="docutils literal"><span class="pre">True</span></tt> for a statement of the form <tt class="docutils literal"><span class="pre">key</span> <span class="pre">in</span> <span class="pre">map</span></tt>, if
the given key is in the map, <tt class="docutils literal"><span class="pre">False</span></tt> otherwise.</li>
</ul>
<p>One of the great benefits of a dictionary is the fact that given a key,
we can look up the associated data value very quickly. In order to
provide this fast look up capability, we need an implementation that
supports an efficient search. We could use a list with sequential or
binary search but it would be even better to use a hash table as
described above since looking up an item in a hash table can approach
<span class="math">\(O(1)\)</span> performance.</p>
<p>In Listing&nbsp;{hashtablecodeconstructor} we use two lists to create a
<tt class="docutils literal"><span class="pre">HashTable</span></tt> class that implements the Map abstract data type. One
list, called <tt class="docutils literal"><span class="pre">slots</span></tt>, will hold the key items and a parallel list,
called <tt class="docutils literal"><span class="pre">data</span></tt>, will hold the data values. When we look up a key, the
corresponding position in the data list will hold the associated data
value. We will treat the key list as a hash table using the ideas
presented earlier. Note that the initial size for the hash table has
been chosen to be 11. Although this is arbitrary, it is important that
the size be a prime number so that the collision resolution algorithm
can be as efficient as possible.</p>
<div class="highlight-python"><pre>[caption={Map ADT Implementation--Constructor},label=hashtablecodeconstructor,float=htb]
class HashTable:
    def __init__(self):
        self.size = 11
        self.slots = [None] * self.size
        self.data = [None] * self.size</pre>
</div>
<p><tt class="docutils literal"><span class="pre">hashfunction</span></tt> implements the simple remainder method. The collision
resolution technique is linear probing with a “plus 1” rehash function.
The <tt class="docutils literal"><span class="pre">put</span></tt> function (see Listing&nbsp;{hashtablecodestore}) assumes that
there will eventually be an empty slot unless the key is already present
in the <tt class="docutils literal"><span class="pre">self.slots</span></tt>. It computes the original hash value and if that
slot is not empty, iterates the <tt class="docutils literal"><span class="pre">rehash</span></tt> function until an empty slot
occurs. If a nonempty slot already contains the key, the old data value
is replaced with the new data value.</p>
<div class="highlight-python"><pre>[caption={Map ADT Implementation--Put Method},label=hashtablecodestore,index={store,hashfunction,rehash},float=htb]
def put(self,key,data):
  hashvalue = self.hashfunction(key,len(self.slots))

  if self.slots[hashvalue] == None:
    self.slots[hashvalue] = key
    self.data[hashvalue] = data
  else:
    if self.slots[hashvalue] == key:
      self.data[hashvalue] = data  #replace
    else:
      nextslot = self.rehash(hashvalue,len(self.slots))
      while self.slots[nextslot] != None and \
                      self.slots[nextslot] != key:
        nextslot = self.rehash(nextslot,len(self.slots))

      if self.slots[nextslot] == None:
        self.slots[nextslot]=key
        self.data[nextslot]=data
      else:
        self.data[nextslot] = data #replace

def hashfunction(self,key,size):
     return key%size

def rehash(self,oldhash,size):
    return (oldhash+1)%size</pre>
</div>
<p>Likewise, the <tt class="docutils literal"><span class="pre">get</span></tt> function (see Listing&nbsp;{hashtablecodesearch})
begins by computing the initial hash value. If the value is not in the
initial slot, <tt class="docutils literal"><span class="pre">rehash</span></tt> is used to locate the next possible position.
Notice that line 15 guarantees that the search will terminate by
checking to make sure that we have not returned to the initial slot. If
that happens, we have exhausted all possible slots and the item must not
be present.</p>
<p>The final methods of the <tt class="docutils literal"><span class="pre">HashTable</span></tt> class provide additional
dictionary functionality. We overload the {__getitem__} and
{__setitem__} methods to allow access using``[]``. This means that
once a <tt class="docutils literal"><span class="pre">HashTable</span></tt> has been created, the familiar index operator will
be available. We leave the remaining methods as exercises.</p>
<div class="highlight-python"><pre>[caption={Map ADT Implementation--Search Method},
label=hashtablecodesearch,index={get,\_\_getitem\_\_,\_\_setitem\_\_},float=htb]
def get(self,key):
  startslot = self.hashfunction(key,len(self.slots))

  data = None
  stop = False
  found = False
  position = startslot
  while self.slots[position] != None and  \
                       not found and not stop:
     if self.slots[position] == key:
       found = True
       data = self.data[position]
     else:
       position=self.rehash(position,len(self.slots))
       if position == startslot:
           stop = True
  return data

def __getitem__(self,key):
    return self.get(key)

def __setitem__(self,key,data):
    self.put(key,data)</pre>
</div>
<p>The following session shows the <tt class="docutils literal"><span class="pre">HashTable</span></tt> class in action. First we
will create a hash table and store some items with integer keys and
string data values.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="o">=</span><span class="n">HashTable</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">54</span><span class="p">]</span><span class="o">=</span><span class="s">&quot;cat&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">26</span><span class="p">]</span><span class="o">=</span><span class="s">&quot;dog&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">93</span><span class="p">]</span><span class="o">=</span><span class="s">&quot;lion&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">17</span><span class="p">]</span><span class="o">=</span><span class="s">&quot;tiger&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">77</span><span class="p">]</span><span class="o">=</span><span class="s">&quot;bird&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">31</span><span class="p">]</span><span class="o">=</span><span class="s">&quot;cow&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">44</span><span class="p">]</span><span class="o">=</span><span class="s">&quot;goat&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">55</span><span class="p">]</span><span class="o">=</span><span class="s">&quot;pig&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">20</span><span class="p">]</span><span class="o">=</span><span class="s">&quot;chicken&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="o">.</span><span class="n">slots</span>
<span class="go">[77, 44, 55, 20, 26, 93, 17, None, None, 31, 54]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="o">.</span><span class="n">data</span>
<span class="go">[&#39;bird&#39;, &#39;goat&#39;, &#39;pig&#39;, &#39;chicken&#39;, &#39;dog&#39;, &#39;lion&#39;,</span>
<span class="go">       &#39;tiger&#39;, None, None, &#39;cow&#39;, &#39;cat&#39;]</span>
</pre></div>
</div>
<p>Next we will access and modify some items in the hash table. Note that
the value for the key 20 is being replaced.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">20</span><span class="p">]</span>
<span class="go">&#39;chicken&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">17</span><span class="p">]</span>
<span class="go">&#39;tiger&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">20</span><span class="p">]</span><span class="o">=</span><span class="s">&#39;duck&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="p">[</span><span class="mi">20</span><span class="p">]</span>
<span class="go">&#39;duck&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">H</span><span class="o">.</span><span class="n">data</span>
<span class="go">[&#39;bird&#39;, &#39;goat&#39;, &#39;pig&#39;, &#39;duck&#39;, &#39;dog&#39;, &#39;lion&#39;,</span>
<span class="go">       &#39;tiger&#39;, None, None, &#39;cow&#39;, &#39;cat&#39;]</span>
<span class="go">&gt;&gt; print(H[99])</span>
<span class="go">None</span>
</pre></div>
</div>
</div>
<div class="section" id="analysis-of-hashing">
<h4>Analysis of Hashing<a class="headerlink" href="#analysis-of-hashing" title="Permalink to this headline">¶</a></h4>
<p>We stated earlier that in the best case hashing would provide a
<span class="math">\(O(1)\)</span>, constant time search technique. However, due to
collisions, the number of comparisons is typically not so simple. Even
though a complete analysis of hashing is beyond the scope of this text,
we can state some well-known results that approximate the number of
comparisons necessary to search for an item.</p>
<p>The most important piece of information we need to analyze the use of a
hash table is the load factor, <span class="math">\(\lambda\)</span>. Conceptually, if
<span class="math">\(\lambda\)</span> is small, then there is a lower chance of collisions,
meaning that items are more likely to be in the slots where they belong.
If <span class="math">\(\lambda\)</span> is large, meaning that the table is filling up,
then there are more and more collisions. This means that collision
resolution is more difficult, requiring more comparisons to find an
empty slot. With chaining, increased collisions means an increased
number of items on each chain.</p>
<p>As before, we will have a result for both a successful and an
unsuccessful search. For a successful search using open addressing with
linear probing, the average number of comparisons is approximately
<span class="math">\($\frac{1}{2}\left(1+\frac{1}{1-\lambda}\right)$\)</span> and an
unsuccessful search gives
<span class="math">\($\frac{1}{2}\left(1+\left(\frac{1}{1-\lambda}\right)^2\right)$\)</span>
If we are using chaining, the average number of comparisons is
<span class="math">\($1 + \frac {\lambda}{2} $\)</span> for the successful case, and simply
<span class="math">\(\lambda\)</span> comparisons if the search is unsuccessful.</p>
</div>
</div>
</div>
<div class="section" id="sorting">
<h2>Sorting<a class="headerlink" href="#sorting" title="Permalink to this headline">¶</a></h2>
<p>Sorting is the process of placing elements from a collection in some
kind of order. For example, a list of words could be sorted
alphabetically or by length. A list of cities could be sorted by
population, by area, or by zip code. We have already seen a number of
algorithms that were able to benefit from having a sorted list (recall
the final anagram example and the binary search).</p>
<p>There are many, many sorting algorithms that have been developed and
analyzed. This suggests that sorting is an important area of study in
computer science. Sorting a large number of items can take a substantial
amount of computing resources. Like searching, the efficiency of a
sorting algorithm is related to the number of items being processed. For
small collections, a complex sorting method may be more trouble than it
is worth. The overhead may be too high. On the other hand, for larger
collections, we want to take advantage of as many improvements as
possible. In this section we will discuss several sorting techniques and
compare them with respect to their running time.</p>
<p>Before getting into specific algorithms, we should think about the
operations that can be used to analyze a sorting process. First, it will
be necessary to compare two values to see which is smaller (or larger).
In order to sort a collection, it will be necessary to have some
systematic way to compare values to see if they are out of order. The
total number of comparisons will be the most common way to measure a
sort procedure. Second, when values are not in the correct position with
respect to one another, it may be necessary to exchange them. This
exchange is a costly operation and the total number of exchanges will
also be important for evaluating the overall efficiency of the
algorithm.</p>
<div class="section" id="the-bubble-sort">
<h3>The Bubble Sort<a class="headerlink" href="#the-bubble-sort" title="Permalink to this headline">¶</a></h3>
<p>The <strong>bubble sort</strong> makes multiple passes through a list. It compares
adjacent items and exchanges those that are out of order. Each pass
through the list places the next largest value in its proper place. In
essence, each item “bubbles” up to the location where it belongs.</p>
<p>Figure&nbsp;{bubblepass} shows the first pass of a bubble sort. The shaded
items are being compared to see if they are out of order. If there are
<em>n</em> items in the list, then there are <span class="math">\(n-1\)</span> pairs of items that
need to be compared on the first pass. It is important to note that once
the largest value in the list is part of a pair, it will continually be
moved along until the pass is complete.</p>
<blockquote>
<div><img alt="image12" src="_images/bubblepass.png" /> {<tt class="docutils literal"><span class="pre">bubbleSort</span></tt>: The First Pass} {bubblepass}</div></blockquote>
<p>At the start of the second pass, the largest value is now in place.
There are <span class="math">\(n-1\)</span> items left to sort, meaning that there will be
<span class="math">\(n-2\)</span> pairs. Since each pass places the next largest value in
place, the total number of passes necessary will be <span class="math">\(n-1\)</span>. After
completing the <span class="math">\(n-1\)</span> passes, the smallest item must be in the
correct position with no further processing required. Listing&nbsp;{bubble}
shows the complete <tt class="docutils literal"><span class="pre">bubbleSort</span></tt> function. It takes the list as a
parameter, and modifies it by exchanging items as necessary.</p>
<p>The exchange operation, sometimes called a “swap,” is slightly different
in Python than in most other programming languages. Typically, swapping
two elements in a list requires a temporary storage location (an
additional memory location). A code fragment such as</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">temp</span> <span class="o">=</span> <span class="n">alist</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
<span class="n">alist</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">alist</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
<span class="n">alist</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">temp</span>
</pre></div>
</div>
<p>will exchange the <a href="#id5"><span class="problematic" id="id6">*</span></a>i*th and <a href="#id7"><span class="problematic" id="id8">*</span></a>j*th items in the list. Without the
temporary storage, one of the values would be overwritten.</p>
<p>In Python, it is possible to perform simultaneous assignment. The
statement <tt class="docutils literal"><span class="pre">a,b=b,a</span></tt> will result in two assignment statements being
done at the same time (see Figure&nbsp;{pythonswap}). Using simultaneous
assignment, the exchange operation can be done in one statement.</p>
<p>Listing&nbsp;{bubble} shows the complete Python implementation for the bubble
sort. Lines 5-7 perform the exchange of the <span class="math">\(i\)</span> and
:math:<a href="#id9"><span class="problematic" id="id10">`</span></a>(i+1)`th items using the three–step procedure described
earlier. Note that we could also have used the simultaneous assignment
to swap the items.</p>
<blockquote>
<div><img alt="image13" src="_images/swap.png" /> {Exchanging Two Values in Python} {pythonswap}</div></blockquote>
<div class="highlight-python"><pre>[caption={A Bubble Sort},label=bubble,index={bubbleSort},float=htb]
def bubbleSort(alist):
    for passnum in range(len(alist)-1,0,-1):
        for i in range(passnum):
            if alist[i]&gt;alist[i+1]:
                temp = alist[i]
                alist[i] = alist[i+1]
                alist[i+1] = temp</pre>
</div>
<p>To analyze the bubble sort, we should note that regardless of how the
items are arranged in the initial list, <span class="math">\(n-1\)</span> passes will be
made to sort a list of size <em>n</em>. Table&nbsp;{bubbleanalysis} shows the number
of comparisons for each pass. The total number of comparisons is the sum
of the first <span class="math">\(n-1\)</span> integers. Recall that the sum of the first
<em>n</em> integers is <span class="math">\(\frac{1}{2}n^{2} + \frac{1}{2}n\)</span>. The sum of
the first <span class="math">\(n-1\)</span> integers is
<span class="math">\(\frac{1}{2}n^{2} + \frac{1}{2}n - n\)</span>, which is
<span class="math">\(\frac{1}{2}n^{2} - \frac{1}{2}n\)</span>. This is still
<span class="math">\(O(n^{2})\)</span> comparisons. In the best case, if the list is already
ordered, no exchanges will be made. However, in the worst case, every
comparison will cause an exchange. On average, we exchange half of the
time.</p>
<blockquote>
<div><blockquote>
<div><dl class="docutils">
<dt><strong>Pass</strong> &amp; <strong>Comparisons</strong></dt>
<dd>1 &amp; <span class="math">\(n-1\)</span>
2 &amp; <span class="math">\(n-2\)</span>
3 &amp; <span class="math">\(n-3\)</span>
... &amp;
<span class="math">\(n-1\)</span> &amp; <span class="math">\(1\)</span></dd>
</dl>
</div></blockquote>
<p>{Comparisons for Each Pass of Bubble Sort} {bubbleanalysis}</p>
</div></blockquote>
<p>A bubble sort is often considered the most inefficient sorting method
since it must exchange items before the final location is known. These
“wasted” exchange operations are very costly. However, because the
bubble sort makes passes through the entire unsorted portion of the
list, it has the capability to do something most sorting algorithms
cannot. In particular, if during a pass there are no exchanges, then we
know that the list must be sorted. A bubble sort can be modified to stop
early if it finds that the list has become sorted. This means that for
lists that require just a few passes, a bubble sort may have an
advantage in that it will recognize the sorted list and stop.
Listing&nbsp;{shortbubble} shows this modification, which is often referred
to as the <strong>short bubble</strong>.</p>
<div class="highlight-python"><pre>[caption={A Modified Bubble Sort},label=shortbubble,index={shortBubbleSort},float=htb]
def shortBubbleSort(alist):
    exchanges = True
    passnum = len(alist)-1
    while passnum &gt; 0 and exchanges:
       exchanges = False
       for i in range(passnum):
           if alist[i]&gt;alist[i+1]:
               exchanges = True
               temp = alist[i]
               alist[i] = alist[i+1]
               alist[i+1] = temp
       passnum = passnum-1</pre>
</div>
</div>
<div class="section" id="the-selection-sort">
<h3>The Selection Sort<a class="headerlink" href="#the-selection-sort" title="Permalink to this headline">¶</a></h3>
<p>The <strong>selection sort</strong> improves on the bubble sort by making only one
exchange for every pass through the list. In order to do this, a
selection sort looks for the largest value as it makes a pass and, after
completing the pass, places it in the proper location. As with a bubble
sort, after the first pass, the largest item is in the correct place.
After the second pass, the next largest is in place. This process
continues and requires <span class="math">\(n-1\)</span> passes to sort <em>n</em> items, since the
final item must be in place after the :math:<a href="#id11"><span class="problematic" id="id12">`</span></a>(n-1)`st pass.</p>
<p>Figure&nbsp;{selectionsort} shows the entire sorting process. On each pass,
the largest remaining item is selected and then placed in its proper
location. The first pass places 93, the second pass places 77, the third
places 55, and so on. The function is shown in
Listing&nbsp;{selectionsortcode}.</p>
<blockquote>
<div><img alt="image14" src="_images/selectionsort.png" /> {<tt class="docutils literal"><span class="pre">selectionSort</span></tt>} {selectionsort}</div></blockquote>
<div class="highlight-python"><pre>[caption={A Selection Sort},label=selectionsortcode,index={selectionSort},float=htb]
def selectionSort(alist):
   for fillslot in range(len(alist)-1,0,-1):
       positionOfMax=0
       for location in range(1,fillslot+1):
           if alist[location]&gt;alist[positionOfMax]:
               positionOfMax = location

       temp = alist[fillslot]
       alist[fillslot] = alist[positionOfMax]
       alist[positionOfMax] = temp</pre>
</div>
<p>You may see that the selection sort makes the same number of comparisons
as the bubble sort and is therefore also <span class="math">\(O(n^{2})\)</span>. However,
due to the reduction in the number of exchanges, the selection sort
typically executes faster in benchmark studies. In fact, for our list,
the bubble sort makes 20 exchanges, while the selection sort makes only
8.</p>
</div>
<div class="section" id="the-insertion-sort">
<h3>The Insertion Sort<a class="headerlink" href="#the-insertion-sort" title="Permalink to this headline">¶</a></h3>
<p>The <strong>insertion sort</strong>, although still <span class="math">\(O(n^{2})\)</span>, works in a
slightly different way. It always maintains a sorted sublist in the
lower positions of the list. Each new item is then “inserted” back into
the previous sublist such that the sorted sublist is one item larger.
Figure&nbsp;{insertionsort} shows the insertion sorting process. The shaded
items represent the ordered sublists as the algorithm makes each pass.</p>
<blockquote>
<div><img alt="image15" src="_images/insertionsort.png" /> {<tt class="docutils literal"><span class="pre">insertionSort</span></tt>} {insertionsort}</div></blockquote>
<p>We begin by assuming that a list with one item (position <span class="math">\(0\)</span>) is
already sorted. On each pass, one for each item 1 through <span class="math">\(n-1\)</span>,
the current item is checked against those in the already sorted sublist.
As we look back into the already sorted sublist, we shift those items
that are greater to the right. When we reach a smaller item or the end
of the sublist, the current item can be inserted.</p>
<p>Figure&nbsp;{insertionpass} shows the fifth pass in detail. At this point in
the algorithm, a sorted sublist of five items consisting of 17, 26, 54,
77, and 93 exists. We want to insert 31 back into the already sorted
items. The first comparison against 93 causes 93 to be shifted to the
right. 77 and 54 are also shifted. When the item 26 is encountered, the
shifting process stops and 31 is placed in the open position. Now we
have a sorted sublist of six items.</p>
<blockquote>
<div><img alt="image16" src="_images/insertionpass.png" /> {<tt class="docutils literal"><span class="pre">insertionSort</span></tt>: Fifth Pass of the Sort}
{insertionpass}</div></blockquote>
<p>The implementation of <tt class="docutils literal"><span class="pre">insertionSort</span></tt> (Listing&nbsp;{insertion}) shows that
there are again <span class="math">\(n-1\)</span> passes to sort <em>n</em> items. The iteration
starts at position 1 and moves through position <span class="math">\(n-1\)</span>, as these
are the items that need to be inserted back into the sorted sublists.
Line 8 performs the shift operation that moves a value up one position
in the list, making room behind it for the insertion. Remember that this
is not a complete exchange as was performed in the previous algorithms.</p>
<p>The maximum number of comparisons for an insertion sort is the sum of
the first <span class="math">\(n-1\)</span> integers. Again, this is <span class="math">\(O(n^{2})\)</span>.
However, in the best case, only one comparison needs to be done on each
pass. This would be the case for an already sorted list.</p>
<p>One note about shifting versus exchanging is also important. In general,
a shift operation requires approximately a third of the processing work
of an exchange since only one assignment is performed. In benchmark
studies, insertion sort will show very good performance.</p>
<div class="highlight-python"><pre>[caption={\texttt{insertionSort}},label=insertion,index={insertionSort},float=htb]
def insertionSort(alist):
   for index in range(1,len(alist)):

     currentvalue = alist[index]
     position = index

     while position&gt;0 and alist[position-1]&gt;currentvalue:
         alist[position]=alist[position-1]
         position = position-1

     alist[position]=currentvalue</pre>
</div>
</div>
<div class="section" id="the-shell-sort">
<h3>The Shell Sort<a class="headerlink" href="#the-shell-sort" title="Permalink to this headline">¶</a></h3>
<p>The <strong>shell sort</strong>, sometimes called the “diminishing increment sort,”
improves on the insertion sort by breaking the original list into a
number of smaller sublists, each of which is sorted using an insertion
sort. The unique way that these sublists are chosen is the key to the
shell sort. Instead of breaking the list into sublists of contiguous
items, the shell sort uses an increment <tt class="docutils literal"><span class="pre">i</span></tt>, sometimes called the
<strong>gap</strong>, to create a sublist by choosing all items that are <tt class="docutils literal"><span class="pre">i</span></tt> items
apart.</p>
<p>This can be seen in Figure&nbsp;{incrementsA}. This list has nine items. If
we use an increment of three, there are three sublists, each of which
can be sorted by an insertion sort. After completing these sorts, we get
the list shown in Figure&nbsp;{incrementsB}. Although this list is not
completely sorted, something very interesting has happened. By sorting
the sublists, we have moved the items closer to where they actually
belong.</p>
<blockquote>
<div><p><img alt="image17" src="_images/shellsortA.png" /> {A Shell Sort with Increments of Three} {incrementsA}</p>
<p><img alt="image18" src="_images/shellsortB.png" /> {A Shell Sort after Sorting Each Sublist} {incrementsB}</p>
</div></blockquote>
<p>Figure&nbsp;{incrementsC} shows a final insertion sort using an increment of
one; in other words, a standard insertion sort. Note that by performing
the earlier sublist sorts, we have now reduced the total number of
shifting operations necessary to put the list in its final order. For
this case, we need only four more shifts to complete the process.</p>
<blockquote>
<div><p><img alt="image19" src="_images/shellsortC.png" /> {ShellSort: A Final Insertion Sort with Increment of 1}
{incrementsC}</p>
<p><img alt="image20" src="_images/shellsortD.png" /> {Initial Sublists for a Shell Sort} {incrementsD}</p>
</div></blockquote>
<p>We said earlier that the way in which the increments are chosen is the
unique feature of the shell sort. The function shown in Listing&nbsp;{shell}
uses a different set of increments. In this case, we begin with
<span class="math">\(\frac {n}{2}\)</span> sublists. On the next pass,
<span class="math">\(\frac {n}{4}\)</span> sublists are sorted. Eventually, a single list is
sorted with the basic insertion sort. Figure&nbsp;{incrementsD} shows the
first sublists for our example using this increment.</p>
<div class="highlight-python"><pre>[caption={shellSort},label=shell,index={shellSort,gapInsertionSort},float=htb]
def shellSort(alist):
    sublistcount = len(alist)//2
    while sublistcount &gt; 0:

      for startposition in range(sublistcount):
        gapInsertionSort(alist,startposition,sublistcount)

      print("After increments of size",sublistcount,
                                   "The list is",alist)

      sublistcount = sublistcount // 2

def gapInsertionSort(alist,start,gap):
    for i in range(start+gap,len(alist),gap):

        currentvalue = alist[i]
        position = i

        while position&gt;=gap and \
                alist[position-gap]&gt;currentvalue:
            alist[position]=alist[position-gap]
            position = position-gap

        alist[position]=currentvalue</pre>
</div>
<p>The following invocation of the <tt class="docutils literal"><span class="pre">shellSort</span></tt> function shows the
partially sorted lists after each increment, with the final sort being
an insertion sort with an increment of one.</p>
<p>{}</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">alist</span><span class="o">=</span><span class="p">[</span><span class="mi">54</span><span class="p">,</span><span class="mi">26</span><span class="p">,</span><span class="mi">93</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">77</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">44</span><span class="p">,</span><span class="mi">55</span><span class="p">,</span><span class="mi">20</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">shellSort</span><span class="p">(</span><span class="n">alist</span><span class="p">)</span>
<span class="go">After increments of size 4 the list is</span>
<span class="go">          [20, 26, 44, 17, 54, 31, 93, 55, 77]</span>
<span class="go">After increments of size 2 the list is</span>
<span class="go">          [20, 17, 44, 26, 54, 31, 77, 55, 93]</span>
<span class="go">After increments of size 1 the list is</span>
<span class="go">          [17, 20, 26, 31, 44, 54, 55, 77, 93]</span>
</pre></div>
</div>
<p>At first glance you may think that a shell sort cannot be better than an
insertion sort, since it does a complete insertion sort as the last
step. It turns out, however, that this final insertion sort does not
need to do very many comparisons (or shifts) since the list has been
pre-sorted by earlier incremental insertion sorts, as described above.
In other words, each pass produces a list that is “more sorted” than the
previous one. This makes the final pass very efficient.</p>
<p>Although a general analysis of the shell sort is well beyond the scope
of this text, we can say that it tends to fall somewhere between
<span class="math">\(O(n)\)</span> and <span class="math">\(O(n^{2})\)</span>, based on the behavior described
above. For the increments shown in Listing&nbsp;{shell}, the performance is
<span class="math">\(O(n^{2})\)</span>. By changing the increment, for example using
<span class="math">\(2^{k}-1\)</span> (1, 3, 7, 15, 31, and so on), a shell sort can perform
at <span class="math">\(O(n^{\frac {3}{2}})\)</span>.</p>
</div>
<div class="section" id="the-merge-sort">
<h3>The Merge Sort<a class="headerlink" href="#the-merge-sort" title="Permalink to this headline">¶</a></h3>
<p>{} We now turn our attention to using a divide and conquer strategy as a
way to improve the performance of sorting algorithms. The first
algorithm we will study is the <strong>merge sort</strong>. Merge sort is a recursive
algorithm that continually splits a list in half. If the list is empty
or has one item, it is sorted by definition (the base case). If the list
has more than one item, we split the list and recursively invoke a merge
sort on both halves. Once the two halves are sorted, the fundamental
operation, called a <strong>merge</strong>, is performed. Merging is the process of
taking two smaller sorted lists and combining them together into a
single, sorted, new list. Figure&nbsp;{mergesortA} shows our familiar example
list as it is being split by <tt class="docutils literal"><span class="pre">mergeSort</span></tt>. Figure&nbsp;{mergesortB} shows
the simple lists, now sorted, as they are merged back together.</p>
<blockquote>
<div><p>[Splitting the List in a Merge Sort] {</p>
<p><img alt="image21" src="_images/mergesortA.png" /> {mergesortA} } [Lists as They Are Merged Together] {</p>
<p><img alt="image22" src="_images/mergesortB.png" /> {mergesortB} } {Splitting and Merging in a Merge Sort}</p>
</div></blockquote>
<div class="highlight-python"><pre>[caption={mergeSort},label=merge,index={mergeSort},float=htb]
def mergeSort(alist):
    print("Splitting ",alist)
    if len(alist)&gt;1:
        mid = len(alist)//2
        lefthalf = alist[:mid]
        righthalf = alist[mid:]

        mergeSort(lefthalf)
        mergeSort(righthalf)

        i=0
        j=0
        k=0
        while i&lt;len(lefthalf) and j&lt;len(righthalf):
            if lefthalf[i]&lt;righthalf[j]:
                alist[k]=lefthalf[i]
                i=i+1
            else:
                alist[k]=righthalf[j]
                j=j+1
            k=k+1

        while i&lt;len(lefthalf):
            alist[k]=lefthalf[i]
            i=i+1
            k=k+1

        while j&lt;len(righthalf):
            alist[k]=righthalf[j]
            j=j+1
            k=k+1
    print("Merging ",alist)</pre>
</div>
<p>The <tt class="docutils literal"><span class="pre">mergeSort</span></tt> function shown in Listing&nbsp;{merge} begins by asking the
base case question. If the length of the list is less than or equal to
one, then we already have a sorted list and no more processing is
necessary. If, on the other hand, the length is greater than one, then
we use the Python <tt class="docutils literal"><span class="pre">slice</span></tt> operation to extract the left and right
halves. It is important to note that the list may not have an even
number of items. That does not matter, as the lengths will differ by at
most one.</p>
<blockquote>
<div><div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">b</span><span class="o">=</span><span class="p">[</span><span class="mi">54</span><span class="p">,</span><span class="mi">26</span><span class="p">,</span><span class="mi">93</span><span class="p">,</span><span class="mi">17</span><span class="p">,</span><span class="mi">77</span><span class="p">,</span><span class="mi">31</span><span class="p">,</span><span class="mi">44</span><span class="p">,</span><span class="mi">55</span><span class="p">,</span><span class="mi">20</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mergeSort</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="go">Splitting  [54, 26, 93, 17, 77, 31, 44, 55, 20]</span>
<span class="go">Splitting  [54, 26, 93, 17]</span>
<span class="go">Splitting  [54, 26]</span>
<span class="go">Splitting  [54]</span>
<span class="go">Merging  [54]</span>
<span class="go">Splitting  [26]</span>
<span class="go">Merging  [26]</span>
<span class="go">Merging  [26, 54]</span>
<span class="go">Splitting  [93, 17]</span>
<span class="go">Splitting  [93]</span>
<span class="go">Merging  [93]</span>
<span class="go">Splitting  [17]</span>
<span class="go">Merging  [17]</span>
<span class="go">Merging  [17, 93]</span>
<span class="go">Merging  [17, 26, 54, 93]</span>
<span class="go">Splitting  [77, 31, 44, 55, 20]</span>
<span class="go">Splitting  [77, 31]</span>
<span class="go">Splitting  [77]</span>
<span class="go">Merging  [77]</span>
<span class="go">Splitting  [31]</span>
<span class="go">Merging  [31]</span>
<span class="go">Merging  [31, 77]</span>
<span class="go">Splitting  [44, 55, 20]</span>
<span class="go">Splitting  [44]</span>
<span class="go">Merging  [44]</span>
<span class="go">Splitting  [55, 20]</span>
<span class="go">Splitting  [55]</span>
<span class="go">Merging  [55]</span>
<span class="go">Splitting  [20]</span>
<span class="go">Merging  [20]</span>
<span class="go">Merging  [20, 55]</span>
<span class="go">Merging  [20, 44, 55]</span>
<span class="go">Merging  [20, 31, 44, 55, 77]</span>
<span class="go">Merging  [17, 20, 26, 31, 44, 54, 55, 77, 93]</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
</div></blockquote>
<p>{-} Once the <tt class="docutils literal"><span class="pre">mergeSort</span></tt> function is invoked on the left half and the
right half (lines 8–9), it is assumed they are sorted. The rest of the
function (lines&nbsp;11–31) is responsible for merging the two smaller sorted
lists into a larger sorted list. Notice that the merge operation places
the items back into the original list (<tt class="docutils literal"><span class="pre">alist</span></tt>) one at a time by
repeatedly taking the smallest item from the sorted lists.</p>
<p>The <tt class="docutils literal"><span class="pre">mergeSort</span></tt> function has been augmented with a <tt class="docutils literal"><span class="pre">print</span></tt> statement
(line 2) to show the contents of the list being sorted at the start of
each invocation. There is also a <tt class="docutils literal"><span class="pre">print</span></tt> statement (line 32) to show
the merging process. The transcript shows the result of executing the
function on our example list. Note that the list with 44, 55, and 20
will not divide evenly. The first split gives [44] and the second gives
[55,20]. It is easy to see how the splitting process eventually yields a
list that can be immediately merged with other sorted lists.</p>
<p>In order to analyze the <tt class="docutils literal"><span class="pre">mergeSort</span></tt> function, we need to consider the
two distinct processes that make up its implementation. First, the list
is split into halves. We already computed (in a binary search) that we
can divide a list in half :math:` log_{2} n` times where <em>n</em> is the
length of the list. The second process is the merge. Each item in the
list will eventually be processed and placed on the sorted list. So the
merge operation which results in a list of size <em>n</em> requires <em>n</em>
operations. The result of this analysis is that <span class="math">\(\log n\)</span> splits,
each of which costs <span class="math">\(n\)</span> for a total of <span class="math">\(n\log n\)</span>
operations. A merge sort is an <span class="math">\(O(n\log n)\)</span> algorithm.</p>
<p>Recall that the slicing operator is <span class="math">\(O(k)\)</span> where k is the size
of the slice. In order to guarantee that <tt class="docutils literal"><span class="pre">mergeSort</span></tt> will be
<span class="math">\(O(n\log n)\)</span> we will need to remove the slice operator. Again,
this is possible if we simply pass the starting and ending indices along
with the list when we make the recursive call. We leave this as an
exercise.</p>
<p>It is important to notice that the <tt class="docutils literal"><span class="pre">mergeSort</span></tt> function requires extra
space to hold the two halves as they are extracted with the slicing
operations. This additional space can be a critical factor if the list
is large and can make this sort problematic when working on large data
sets.</p>
</div>
<div class="section" id="the-quick-sort">
<h3>The Quick Sort<a class="headerlink" href="#the-quick-sort" title="Permalink to this headline">¶</a></h3>
<p>The <strong>quick sort</strong> uses divide and conquer to gain the same advantages
as the merge sort, while not using additional storage. As a trade-off,
however, it is possible that the list may not be divided in half. When
this happens, we will see that performance is diminished.</p>
<p>A quick sort first selects a value, which is called the <strong>pivot value</strong>.
Although there are many different ways to choose the pivot value, we
will simply use the first item in the list. The role of the pivot value
is to assist with splitting the list. The actual position where the
pivot value belongs in the final sorted list, commonly called the
<strong>split point</strong>, will be used to divide the list for subsequent calls to
the quick sort.</p>
<p>Figure&nbsp;{splitvalue} shows that 54 will serve as our first pivot value.
Since we have looked at this example a few times already, we know that
54 will eventually end up in the position currently holding 31. The
<strong>partition</strong> process will happen next. It will find the split point and
at the same time move other items to the appropriate side of the list,
either less than or greater than the pivot value.</p>
<blockquote>
<div><p><img alt="image23" src="_images/firstsplit.png" /> {The First Pivot Value for a Quick Sort} {splitvalue}</p>
<p><img alt="image24" src="_images/partitionA.png" /> {Finding the Split Point for 54} {partitionA}</p>
</div></blockquote>
<p>Partitioning begins by locating two position markers—let’s call them
<tt class="docutils literal"><span class="pre">leftmark</span></tt> and <tt class="docutils literal"><span class="pre">rightmark</span></tt>—at the beginning and end of the remaining
items in the list (positions 1 and 8 in Figure&nbsp;{partitionA}). The goal
of the partition process is to move items that are on the wrong side
with respect to the pivot value while also converging on the split
point. Figure&nbsp;{partitionA} shows this process as we locate the position
of 54.</p>
<p>{}</p>
<p>We begin by incrementing <tt class="docutils literal"><span class="pre">leftmark</span></tt> until we locate a value that is
greater than the pivot value. We then decrement <tt class="docutils literal"><span class="pre">rightmark</span></tt> until we
find a value that is less than the pivot value. At this point we have
discovered two items that are out of place with respect to the eventual
split point. For our example, this occurs at 93 and 20. Now we can
exchange these two items and then repeat the process again.</p>
<p>At the point where <tt class="docutils literal"><span class="pre">rightmark</span></tt> becomes less than <tt class="docutils literal"><span class="pre">leftmark</span></tt>, we
stop. The position of <tt class="docutils literal"><span class="pre">rightmark</span></tt> is now the split point. The pivot
value can be exchanged with the contents of the split point and the
pivot value is now in place (Figure&nbsp;{partitionB}). In addition, all the
items to the left of the split point are less than the pivot value, and
all the items to the right of the split point are greater than the pivot
value. The list can now be divided at the split point and the quick sort
can be invoked recursively on the two halves.</p>
<blockquote>
<div><img alt="image25" src="_images/partitionB.png" /> {Completing the Partition Process to Find the Split Point
for 54} {partitionB}</div></blockquote>
<p>The <tt class="docutils literal"><span class="pre">quickSort</span></tt> function shown in Listing&nbsp;{quick} invokes a recursive
function, <tt class="docutils literal"><span class="pre">quickSortHelper</span></tt>. <tt class="docutils literal"><span class="pre">quickSortHelper</span></tt> begins with the same
base case as the merge sort. If the length of the list is less than or
equal to one, it is already sorted. If it is greater, then it can be
partitioned and recursively sorted. The <tt class="docutils literal"><span class="pre">partition</span></tt> function
implements the process described earlier.</p>
<div class="highlight-python"><pre>[caption={A Quick Sort},label=quick,index={quickSort,quickSortHelper,partition},float=htbp]
def quickSort(alist):
   quickSortHelper(alist,0,len(alist)-1)

def quickSortHelper(alist,first,last):
   if first&lt;last:

       splitpoint = partition(alist,first,last)

       quickSortHelper(alist,first,splitpoint-1)
       quickSortHelper(alist,splitpoint+1,last)


def partition(alist,first,last):
   pivotvalue = alist[first]

   leftmark = first+1
   rightmark = last

   done = False
   while not done:

       while leftmark &lt;= rightmark and \
               alist[leftmark] &lt;= pivotvalue:
           leftmark = leftmark + 1

       while alist[rightmark] &gt;= pivotvalue and \
               rightmark &gt;= leftmark:
           rightmark = rightmark -1

       if rightmark &lt; leftmark:
           done = True
       else:
           temp = alist[leftmark]
           alist[leftmark] = alist[rightmark]
           alist[rightmark] = temp

   temp = alist[first]
   alist[first] = alist[rightmark]
   alist[rightmark] = temp


   return rightmark</pre>
</div>
<p>To analyze the <tt class="docutils literal"><span class="pre">quickSort</span></tt> function, note that for a list of length
<em>n</em>, if the partition always occurs in the middle of the list, there
will again be <span class="math">\(\log n\)</span> divisions. In order to find the split
point, each of the <em>n</em> items needs to be checked against the pivot
value. The result is <span class="math">\(n\log n\)</span>. In addition, there is no need
for additional memory as in the merge sort process.</p>
<p>Unfortunately, in the worst case, the split points may not be in the
middle and can be very skewed to the left or the right, leaving a very
uneven division. In this case, sorting a list of <em>n</em> items divides into
sorting a list of 0 items and a list of <span class="math">\(n-1\)</span> items. Then
sorting a list of <span class="math">\(n-1\)</span> divides into a list of size 0 and a list
of size <span class="math">\(n-2\)</span>, and so on. The result is an <span class="math">\(O(n^{2})\)</span>
sort with all of the overhead that recursion requires.</p>
<p>We mentioned earlier that there are different ways to choose the pivot
value. In particular, we can attempt to alleviate some of the potential
for an uneven division by using a technique called <strong>median of three</strong>.
To choose the pivot value, we will consider the first, the middle, and
the last element in the list. In our example, those are 54, 77, and 20.
Now pick the median value, in our case 54, and use it for the pivot
value (of course, that was the pivot value we used originally). The idea
is that in the case where the the first item in the list does not belong
toward the middle of the list, the median of three will choose a better
“middle” value. This will be particularly useful when the original list
is somewhat sorted to begin with. We leave the implementation of this
pivot value selection as an exercise.</p>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>A sequential search is <span class="math">\(O(n)\)</span> for ordered and unordered
lists.</li>
<li>A binary search of an ordered list is <span class="math">\(O(\log n)\)</span> in the
worst case.</li>
<li>Hash tables can provide constant time searching.</li>
<li>A bubble sort, a selection sort, and an insertion sort are
<span class="math">\(O(n^{2})\)</span> algorithms.</li>
<li>A shell sort improves on the insertion sort by sorting incremental
sublists. It falls between <span class="math">\(O(n)\)</span> and <span class="math">\(O(n^{2})\)</span>.</li>
<li>A merge sort is <span class="math">\(O(n \log n)\)</span>, but requires additional space
for the merging process.</li>
<li>A quick sort is <span class="math">\(O(n \log n)\)</span>, but may degrade to
<span class="math">\(O(n^{2})\)</span> if the split points are not near the middle of the
list. It does not require additional space.</li>
</ul>
</div>
<div class="section" id="key-terms">
<h2>Key Terms<a class="headerlink" href="#key-terms" title="Permalink to this headline">¶</a></h2>
<blockquote>
<div>binary Search &amp; bubble Sort &amp; chaining
clustering &amp; collision &amp; collision resolution
folding method &amp; gap &amp; hash function
hash table &amp; hashing &amp; insertion sort
linear probing &amp; load factor &amp; map
median of three &amp; merge &amp; merge sort
mid-square method &amp; open addressing &amp; partition
perfect hash function &amp; pivot value &amp; quadratic probing
quick sort &amp; rehashing &amp; selection sort
sequential search &amp; shell sort &amp; short bubble
slot &amp; split point &amp;</div></blockquote>
</div>
<div class="section" id="discussion-questions">
<h2>Discussion Questions<a class="headerlink" href="#discussion-questions" title="Permalink to this headline">¶</a></h2>
<ol class="arabic">
<li><p class="first">Using the hash table performance formulas given in the chapter,
compute the average number of comparisons necessary when the table is</p>
<ul class="simple">
<li>10% full</li>
<li>25% full</li>
<li>50% full</li>
<li>75% full</li>
<li>90% full</li>
<li>99% full</li>
</ul>
<p>At what point do you think the hash table is too small? Explain.</p>
</li>
<li><p class="first">Modify the hash function for strings to use positional weightings.</p>
</li>
<li><p class="first">We used a hash function for strings that weighted the characters by
position. Devise an alternative weighting scheme. What are the biases
that exist with these functions?</p>
</li>
<li><p class="first">Research perfect hash functions. Using a list of names (classmates,
family members, etc.), generate the hash values using the perfect
hash algorithm.</p>
</li>
<li><p class="first">Generate a random list of integers. Show how this list is sorted by
the following algorithms:</p>
<ul class="simple">
<li>bubble sort</li>
<li>selection sort</li>
<li>insertion sort</li>
<li>shell sort (you decide on the increments)</li>
<li>merge sort</li>
<li>quick sort (you decide on the pivot value)</li>
</ul>
</li>
<li><p class="first">Consider the following list of integers: [1,2,3,4,5,6,7,8,9,10]. Show
how this list is sorted by the following algorithms:</p>
<ul class="simple">
<li>bubble sort</li>
<li>selection sort</li>
<li>insertion sort</li>
<li>shell sort (you decide on the increments)</li>
<li>merge sort</li>
<li>quick sort (you decide on the pivot value)</li>
</ul>
</li>
<li><p class="first">Consider the following list of integers: [10,9,8,7,6,5,4,3,2,1]. Show
how this list is sorted by the following algorithms:</p>
<ul class="simple">
<li>bubble sort</li>
<li>selection sort</li>
<li>insertion sort</li>
<li>shell sort (you decide on the increments)</li>
<li>merge sort</li>
<li>quick sort (you decide on the pivot value)</li>
</ul>
</li>
<li><p class="first">Consider the list of characters: [<tt class="docutils literal"><span class="pre">'P','Y','T','H','O','N'</span></tt>]. Show
how this list is sorted using the following algorithms:</p>
<ul class="simple">
<li>bubble sort</li>
<li>selection sort</li>
<li>insertion sort</li>
<li>shell sort (you decide on the increments)</li>
<li>merge sort</li>
<li>quick sort (you decide on the pivot value)</li>
</ul>
</li>
<li><p class="first">Devise alternative strategies for choosing the pivot value in quick
sort. For example, pick the middle item. Re-implement the algorithm
and then execute it on random data sets. Under what criteria does
your new strategy perform better or worse than the strategy from this
chapter?</p>
</li>
</ol>
</div>
<div class="section" id="programming-exercises">
<h2>Programming Exercises<a class="headerlink" href="#programming-exercises" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li>Set up a random experiment to test the difference between a
sequential search and a binary search on a list of integers.</li>
<li>Use the binary search functions given in the text (recursive and
iterative). Generate a random, ordered list of integers and do a
benchmark analysis for each one. What are your results? Can you
explain them?</li>
<li>Implement the binary search using recursion without the slice
operator. Recall that you will need to pass the list along with the
starting and ending index values for the sublist. Generate a random,
ordered list of integers and do a benchmark analysis.</li>
<li>Implement the <tt class="docutils literal"><span class="pre">len</span></tt> method (__len__) for the hash table Map ADT
implementation.</li>
<li>Implement the <tt class="docutils literal"><span class="pre">in</span></tt> method (__contains__) for the hash table Map
ADT implementation.</li>
<li>How can you delete items from a hash table that uses chaining for
collision resolution? How about if open addressing is used? What are
the special circumstances that must be handled? Implement the <tt class="docutils literal"><span class="pre">del</span></tt>
method for the <tt class="docutils literal"><span class="pre">HashTable</span></tt> class.</li>
<li>In the hash table map implementation, the hash table size was chosen
to be 101. If the table gets full, this needs to be increased.
Re-implement the <tt class="docutils literal"><span class="pre">put</span></tt> method so that the table will automatically
resize itself when the loading factor reaches a predetermined value
(you can decide the value based on your assessment of load versus
performance).</li>
<li>Implement quadratic probing as a rehash technique.</li>
<li>Using a random number generator, create a list of 500 integers.
Perform a benchmark analysis using some of the sorting algorithms
from this chapter. What is the difference in execution speed?</li>
<li>Implement the bubble sort using simultaneous assignment.</li>
<li>A bubble sort can be modified to “bubble” in both directions. The
first pass moves “up” the list, and the second pass moves “down.”
This alternating pattern continues until no more passes are
necessary. Implement this variation and describe under what
circumstances it might be appropriate.</li>
<li>Implement the selection sort using simultaneous assignment.</li>
<li>Perform a benchmark analysis for a shell sort, using different
increment sets on the same list.</li>
<li>Implement the <tt class="docutils literal"><span class="pre">mergeSort</span></tt> function without using the slice
operator.</li>
<li>One way to improve the quick sort is to use an insertion sort on
lists that have a small length (call it the “partition limit”). Why
does this make sense? Re-implement the quick sort and use it to sort
a random list of integers. Perform an analysis using different list
sizes for the partition limit.</li>
<li>Implement the median-of-three method for selecting a pivot value as a
modification to <tt class="docutils literal"><span class="pre">quickSort</span></tt>. Run an experiment to compare the two
techniques.</li>
</ol>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="trees.html" title="Trees"
             >next</a> |</li>
        <li class="right" >
          <a href="recursion.html" title="Recursion"
             >previous</a> |</li>
        <li><a href="index.html">Problem Solving with Algorithms and Data Structures 3.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011, Brad Miller, Kent Lee, David Ranum.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.2pre.
    </div>
  </body>
</html>